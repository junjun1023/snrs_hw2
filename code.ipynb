{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper: Link Prediction Based on Graph Neural Networks (NeurIPS 2018)\n",
    "# Example: https://github.com/rusty1s/pytorch_geometric/blob/99a496e077a4d41417c7d927df7730fd984004b9/examples/seal_link_pred.py#L90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "large-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os.path as osp\n",
    "from itertools import chain\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "from itertools import repeat, product\n",
    "from torch import Tensor\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.nn import ModuleList, Linear, Conv1d, MaxPool1d\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv, global_sort_pool\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader, Dataset\n",
    "from torch_geometric.utils import (negative_sampling, add_self_loops,\n",
    "                                   train_test_split_edges, k_hop_subgraph,\n",
    "                                   to_scipy_sparse_matrix, to_undirected, \n",
    "                                   contains_self_loops, add_remaining_self_loops, \n",
    "                                   is_undirected, segregate_self_loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "weighted-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-forum",
   "metadata": {},
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "quick-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(x):\n",
    "    if not isinstance(x, (tuple, list)):\n",
    "        x = [x]\n",
    "    return x\n",
    "\n",
    "\n",
    "def files_exist(files):\n",
    "    return len(files) != 0 and all(osp.exists(f) for f in files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "available-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(InMemoryDataset):\n",
    "    \n",
    "    def __init__(self, num_hops, root=None, split=\"train\"):\n",
    "        \n",
    "        self.num_hops = num_hops\n",
    "        super().__init__(root=root)\n",
    "        \n",
    "        index = ['train', 'valid', \"test\"].index(split)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[index])\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):  \n",
    "        return [\"train.csv\"]\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['SEAL_data_train.pt', 'SEAL_data_valid.pt', 'SEAL_data_test.pt']\n",
    "    \n",
    "    \n",
    "    def process(self):\n",
    "        # Read node features\n",
    "        content = pd.read_csv(os.path.join(self.raw_dir, \"content.csv\"), delimiter=\"\\t\", header=None)\n",
    "        content = content.sort_values(by=[0]).loc[:, 1:].to_numpy()\n",
    "        content = torch.from_numpy(content)\n",
    "        num_nodes = content.size(0)\n",
    "    \n",
    "        \n",
    "        # Read train edge list\n",
    "        train = pd.read_csv(os.path.join(self.raw_dir, \"train.csv\"))\n",
    "        \n",
    "        train_pos = train[ train[\"label\"] == 1]\n",
    "        train_neg = train[ train[\"label\"] == 0]\n",
    "\n",
    "        follower_pos = train_pos[\"from\"].to_numpy().tolist()\n",
    "        followee_pos = train_pos[\"to\"].to_numpy().tolist()\n",
    "        train_pos_edge = torch.tensor([follower_pos, followee_pos], dtype=torch.long)\n",
    "        train_pos_edge, _ = torch_geometric.utils.remove_self_loops(train_pos_edge)\n",
    "        train_pos_edge = to_undirected(train_pos_edge, num_nodes=num_nodes)\n",
    "\n",
    "        self.data = Data(x=content, edge_index=train_pos_edge, num_nodes=num_nodes)\n",
    "        self.__max_z__ = 0\n",
    "        \n",
    "\n",
    "        follower_neg = train_neg[\"from\"].to_numpy().tolist()\n",
    "        followee_neg = train_neg[\"to\"].to_numpy().tolist()\n",
    "        train_neg_edge = torch.tensor([follower_neg, followee_neg], dtype=torch.long)\n",
    "        train_neg_edge = to_undirected(train_neg_edge, num_nodes=num_nodes)\n",
    "        \n",
    "        ### Suppose self-loop must be linked\n",
    "        train_neg_edge, _ = torch_geometric.utils.remove_self_loops(train_neg_edge)\n",
    "    \n",
    "#         train_pos_edge = train_pos_edge.t()\n",
    "#         train_neg_edge = train_neg_edge.t()\n",
    "\n",
    "#         train_pos_edge, valid_pos_edge = train_test_split(train_pos_edge, shuffle=True)\n",
    "#         train_neg_edge, valid_neg_edge = train_test_split(train_neg_edge, shuffle=True)\n",
    "        \n",
    "#         train_pos_edge = train_pos_edge.t()\n",
    "#         valid_pos_edge = valid_pos_edge.t()\n",
    "#         train_neg_edge = train_neg_edge.t()\n",
    "#         valid_neg_edge = valid_neg_edge.t()\n",
    "        \n",
    "        ### DRNL can't handle self-loops\n",
    "        # train_pos_edge, _ = add_self_loops(train_pos_edge, num_nodes=num_nodes)\n",
    "        \n",
    "        \n",
    "        train_pos_list = self.extract_enclosing_subgraphs(\n",
    "            train_pos_edge, train_pos_edge, 1, num_nodes=num_nodes)\n",
    "        train_neg_list = self.extract_enclosing_subgraphs(\n",
    "            train_neg_edge, train_pos_edge, 0, num_nodes=num_nodes)\n",
    "    \n",
    "\n",
    "#         val_pos_list = self.extract_enclosing_subgraphs(\n",
    "#             valid_pos_edge, train_pos_edge, 1, num_nodes=num_nodes)\n",
    "#         val_neg_list = self.extract_enclosing_subgraphs(\n",
    "#             valid_neg_edge, train_pos_edge, 0, num_nodes=num_nodes)\n",
    "        \n",
    "        \n",
    "        # Read test edge list\n",
    "        test = pd.read_csv(os.path.join(self.raw_dir, \"test.csv\"))\n",
    "\n",
    "        test_follower = test[\"from\"].to_numpy().tolist()\n",
    "        test_followee = test[\"to\"].to_numpy().tolist()\n",
    "        test_edge = torch.tensor([test_follower, test_followee], dtype=torch.long)\n",
    "        test_edge, _ = torch_geometric.utils.remove_self_loops(test_edge)\n",
    "        \n",
    "        test_list = self.extract_enclosing_subgraphs(\n",
    "            test_edge, train_pos_edge, 0, num_nodes=num_nodes)\n",
    "\n",
    "\n",
    "        # Convert labels to one-hot features.\n",
    "        for data in chain(train_pos_list, train_neg_list, \n",
    "#                           val_pos_list, val_neg_list, \n",
    "                          test_list):\n",
    "\n",
    "            z = F.one_hot(data.z, self.__max_z__ + 1).to(torch.float)\n",
    "            data.x = torch.cat([z, data.x], 1)\n",
    "\n",
    "        torch.save(self.collate(train_pos_list + train_neg_list),\n",
    "                   self.processed_paths[0])\n",
    "#         torch.save(self.collate(val_pos_list + val_neg_list),\n",
    "#                    self.processed_paths[1])\n",
    "        torch.save(self.collate(test_list), self.processed_paths[2])\n",
    "\n",
    "    \n",
    "    \n",
    "    def extract_enclosing_subgraphs(self, link_index, edge_index, y, num_nodes, scale=\"single\"):\n",
    "        data_list = []\n",
    "        for src, dst in link_index.t().tolist():\n",
    "            sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
    "                [src, dst], self.num_hops, edge_index, relabel_nodes=True, num_nodes=num_nodes)\n",
    "            src, dst = mapping.tolist()\n",
    "            \n",
    "            # Remove target link from the subgraph.\n",
    "            mask1 = (sub_edge_index[0] != src) | (sub_edge_index[1] != dst)\n",
    "            mask2 = (sub_edge_index[0] != dst) | (sub_edge_index[1] != src)\n",
    "            sub_edge_index = sub_edge_index[:, mask1 & mask2]\n",
    "\n",
    "            # Calculate node labeling.\n",
    "            z = self.drnl_node_labeling(sub_edge_index, src, dst,\n",
    "                                        num_nodes=sub_nodes.size(0))\n",
    "\n",
    "            data = Data(x=self.data.x[sub_nodes], z=z,\n",
    "                        edge_index=sub_edge_index, y=y)\n",
    "            data_list.append(data)\n",
    " \n",
    "        return data_list\n",
    "    \n",
    "\n",
    "    def drnl_node_labeling(self, edge_index, src, dst, num_nodes=None):\n",
    "        # Double-radius node labeling (DRNL).\n",
    "        src, dst = (dst, src) if src > dst else (src, dst)\n",
    "        adj = to_scipy_sparse_matrix(edge_index, num_nodes=num_nodes).tocsr()\n",
    "        \n",
    "        idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
    "        adj_wo_src = adj[idx, :][:, idx]\n",
    "        \n",
    "        idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
    "        adj_wo_dst = adj[idx, :][:, idx]\n",
    "\n",
    "        dist2src = shortest_path(adj_wo_dst, directed=False, unweighted=True,\n",
    "                                 indices=src)\n",
    "        dist2src = np.insert(dist2src, dst, 0, axis=0)\n",
    "        dist2src = torch.from_numpy(dist2src)\n",
    "\n",
    "\n",
    "        dist2dst = shortest_path(adj_wo_src, directed=False, unweighted=True,\n",
    "                                 indices=dst - 1)\n",
    "        dist2dst = np.insert(dist2dst, src, 0, axis=0)\n",
    "        dist2dst = torch.from_numpy(dist2dst)\n",
    "\n",
    "        dist = dist2src + dist2dst\n",
    "        dist_over_2, dist_mod_2 = dist // 2, dist % 2\n",
    "\n",
    "        z = 1 + torch.min(dist2src, dist2dst)\n",
    "        z += dist_over_2 * (dist_over_2 + dist_mod_2 - 1)\n",
    "        z[src] = 1.\n",
    "        z[dst] = 1.\n",
    "        z[torch.isnan(z)] = 0.\n",
    "\n",
    "        self.__max_z__ = max(int(z.max()), self.__max_z__)\n",
    "\n",
    "            \n",
    "        return z.to(torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-contract",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "traditional-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGCNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_layers, GNN=GCNConv, k=0.6):\n",
    "        super(DGCNN, self).__init__()\n",
    "\n",
    "        if k < 1:  # Transform percentile to number.\n",
    "            num_nodes = sorted([data.num_nodes for data in train_dataset])\n",
    "            k = num_nodes[int(math.ceil(k * len(num_nodes))) - 1]\n",
    "            k = max(10, k)\n",
    "        self.k = int(k)\n",
    "\n",
    "        self.convs = ModuleList()\n",
    "        self.convs.append(GNN(train_dataset.num_features, hidden_channels))\n",
    "        for i in range(0, num_layers - 1):\n",
    "            self.convs.append(GNN(hidden_channels, hidden_channels))\n",
    "        self.convs.append(GNN(hidden_channels, 1))\n",
    "\n",
    "        conv1d_channels = [16, 32]\n",
    "        total_latent_dim = hidden_channels * num_layers + 1\n",
    "        conv1d_kws = [total_latent_dim, 5]\n",
    "        self.conv1 = Conv1d(1, conv1d_channels[0], conv1d_kws[0],\n",
    "                            conv1d_kws[0])\n",
    "        self.maxpool1d = MaxPool1d(2, 2)\n",
    "        self.conv2 = Conv1d(conv1d_channels[0], conv1d_channels[1],\n",
    "                            conv1d_kws[1], 1)\n",
    "        dense_dim = int((self.k - 2) / 2 + 1)\n",
    "        dense_dim = (dense_dim - conv1d_kws[1] + 1) * conv1d_channels[1]\n",
    "        self.lin1 = Linear(dense_dim, 128)\n",
    "        self.lin2 = Linear(128, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        xs = [x]\n",
    "        for conv in self.convs:\n",
    "            xs += [torch.tanh(conv(xs[-1], edge_index))]\n",
    "        x = torch.cat(xs[1:], dim=-1)\n",
    "\n",
    "        # Global pooling.\n",
    "\n",
    "        x = global_sort_pool(x, batch, self.k)\n",
    "\n",
    "        x = x.unsqueeze(1)  # [num_graphs, 1, k * hidden]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool1d(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [num_graphs, dense_dim]\n",
    "\n",
    "        \n",
    "        # MLP.\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "beautiful-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data.x, data.edge_index, data.batch)\n",
    "        loss = BCEWithLogitsLoss()(logits.view(-1), data.y.to(torch.float))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "\n",
    "    return total_loss / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "patient-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    y_pred, y_true = [], []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        logits = model(data.x, data.edge_index, data.batch)\n",
    "    \n",
    "        pred = torch.nn.Sigmoid()(logits)\n",
    "        \n",
    "        y_pred.append(pred.view(-1).cpu())\n",
    "        y_true.append(data.y.view(-1).cpu().to(torch.float))\n",
    "\n",
    "    return roc_auc_score(torch.cat(y_true), torch.cat(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "executed-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(loader):\n",
    "    model.eval()\n",
    "    \n",
    "    y_pred = []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        logits = model(data.x, data.edge_index, data.batch)\n",
    "        \n",
    "        pred = torch.nn.Sigmoid()(logits)\n",
    "        \n",
    "        y_pred.append(pred.view(-1).cpu().numpy())\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-prague",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "apparent-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-municipality",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cora = Planetoid(root=os.getcwd(), name='Cora')\n",
    "\n",
    "cora_train_dataset = SEALDataset(cora, num_hops=2, split='train')\n",
    "cora_val_dataset = SEALDataset(cora, num_hops=2, split='val')\n",
    "cora_test_dataset = SEALDataset(cora, num_hops=2, split='test')\n",
    "\n",
    "cora_train_loader = DataLoader(cora_train_dataset, batch_size=32, shuffle=True)\n",
    "cora_val_loader = DataLoader(cora_val_dataset, batch_size=32)\n",
    "cora_test_loader = DataLoader(cora_test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "radical-converter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEALDataset(17952)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "resistant-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = DGCNN(hidden_channels=32, num_layers=3).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_auc = test_auc = 0\n",
    "for epoch in range(1, 51):\n",
    "    loss = train(cora_train_loader)\n",
    "    val_auc = test(cora_val_loader)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        test_auc = test(cora_test_loader)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-ensemble",
   "metadata": {},
   "source": [
    "# My Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "bacterial-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath, device):\n",
    "    \n",
    "    model = DGCNN(hidden_channels=32, num_layers=3).to(device)\n",
    "\n",
    "    if os.path.exists(filepath):\n",
    "        print(\"pretrained finded\")\n",
    "        checkpoint = torch.load(filepath)\n",
    "        model.load_state_dict(checkpoint['model_stat'])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_stat'])\n",
    "\n",
    "    else:\n",
    "        print(\"use a new optimizer\")\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "dried-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "defined-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"dataset4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "acting-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = datetime.strftime(datetime.now(), \"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "save = os.path.join(root, \"results\", dataset, date_time)\n",
    "\n",
    "if os.path.exists(save):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "particular-hartford",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "torch.Size([2, 131]) torch.Size([67]) torch.Size([67])\n",
      "torch.Size([2, 114]) torch.Size([63]) torch.Size([63])\n",
      "torch.Size([2, 47]) torch.Size([18]) torch.Size([18])\n",
      "torch.Size([2, 295]) torch.Size([118]) torch.Size([118])\n",
      "torch.Size([2, 44]) torch.Size([19]) torch.Size([19])\n",
      "torch.Size([2, 141]) torch.Size([68]) torch.Size([68])\n",
      "torch.Size([2, 4]) torch.Size([4]) torch.Size([4])\n",
      "torch.Size([2, 25]) torch.Size([11]) torch.Size([11])\n",
      "torch.Size([2, 138]) torch.Size([69]) torch.Size([69])\n",
      "torch.Size([2, 12]) torch.Size([8]) torch.Size([8])\n",
      "torch.Size([2, 20]) torch.Size([11]) torch.Size([11])\n",
      "torch.Size([2, 253]) torch.Size([105]) torch.Size([105])\n",
      "torch.Size([2, 308]) torch.Size([122]) torch.Size([122])\n",
      "torch.Size([2, 34]) torch.Size([17]) torch.Size([17])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 205]) torch.Size([87]) torch.Size([87])\n",
      "torch.Size([2, 39]) torch.Size([16]) torch.Size([16])\n",
      "torch.Size([2, 231]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 231]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 186]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 233]) torch.Size([100]) torch.Size([100])\n",
      "torch.Size([2, 283]) torch.Size([115]) torch.Size([115])\n",
      "torch.Size([2, 327]) torch.Size([133]) torch.Size([133])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 125]) torch.Size([67]) torch.Size([67])\n",
      "torch.Size([2, 45]) torch.Size([19]) torch.Size([19])\n",
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 25]) torch.Size([11]) torch.Size([11])\n",
      "torch.Size([2, 132]) torch.Size([65]) torch.Size([65])\n",
      "torch.Size([2, 11]) torch.Size([9]) torch.Size([9])\n",
      "torch.Size([2, 124]) torch.Size([63]) torch.Size([63])\n",
      "torch.Size([2, 0]) torch.Size([2]) torch.Size([2])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 134]) torch.Size([69]) torch.Size([69])\n",
      "torch.Size([2, 129]) torch.Size([68]) torch.Size([68])\n",
      "torch.Size([2, 140]) torch.Size([67]) torch.Size([67])\n",
      "torch.Size([2, 120]) torch.Size([64]) torch.Size([64])\n",
      "torch.Size([2, 13]) torch.Size([9]) torch.Size([9])\n",
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 150]) torch.Size([70]) torch.Size([70])\n",
      "torch.Size([2, 28]) torch.Size([15]) torch.Size([15])\n",
      "torch.Size([2, 29]) torch.Size([15]) torch.Size([15])\n",
      "torch.Size([2, 172]) torch.Size([80]) torch.Size([80])\n",
      "torch.Size([2, 2]) torch.Size([3]) torch.Size([3])\n",
      "torch.Size([2, 30]) torch.Size([14]) torch.Size([14])\n",
      "torch.Size([2, 51]) torch.Size([19]) torch.Size([19])\n",
      "torch.Size([2, 283]) torch.Size([115]) torch.Size([115])\n",
      "torch.Size([2, 0]) torch.Size([2]) torch.Size([2])\n",
      "torch.Size([2, 116]) torch.Size([64]) torch.Size([64])\n",
      "torch.Size([2, 135]) torch.Size([70]) torch.Size([70])\n",
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 189]) torch.Size([90]) torch.Size([90])\n",
      "torch.Size([2, 285]) torch.Size([116]) torch.Size([116])\n",
      "torch.Size([2, 135]) torch.Size([71]) torch.Size([71])\n",
      "torch.Size([2, 161]) torch.Size([78]) torch.Size([78])\n",
      "torch.Size([2, 176]) torch.Size([81]) torch.Size([81])\n",
      "torch.Size([2, 159]) torch.Size([75]) torch.Size([75])\n",
      "torch.Size([2, 131]) torch.Size([70]) torch.Size([70])\n",
      "torch.Size([2, 157]) torch.Size([72]) torch.Size([72])\n",
      "torch.Size([2, 0]) torch.Size([2]) torch.Size([2])\n",
      "torch.Size([2, 170]) torch.Size([80]) torch.Size([80])\n",
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 21]) torch.Size([11]) torch.Size([11])\n",
      "torch.Size([2, 0]) torch.Size([2]) torch.Size([2])\n",
      "torch.Size([2, 1]) torch.Size([3]) torch.Size([3])\n",
      "torch.Size([2, 231]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 154]) torch.Size([72]) torch.Size([72])\n",
      "torch.Size([2, 27]) torch.Size([12]) torch.Size([12])\n",
      "torch.Size([2, 20]) torch.Size([11]) torch.Size([11])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 111]) torch.Size([62]) torch.Size([62])\n",
      "torch.Size([2, 284]) torch.Size([116]) torch.Size([116])\n",
      "torch.Size([2, 0]) torch.Size([2]) torch.Size([2])\n",
      "torch.Size([2, 13]) torch.Size([9]) torch.Size([9])\n",
      "torch.Size([2, 123]) torch.Size([65]) torch.Size([65])\n",
      "torch.Size([2, 43]) torch.Size([16]) torch.Size([16])\n",
      "torch.Size([2, 13]) torch.Size([8]) torch.Size([8])\n",
      "torch.Size([2, 87]) torch.Size([38]) torch.Size([38])\n",
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 132]) torch.Size([65]) torch.Size([65])\n",
      "torch.Size([2, 5]) torch.Size([5]) torch.Size([5])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 159]) torch.Size([75]) torch.Size([75])\n",
      "torch.Size([2, 7]) torch.Size([5]) torch.Size([5])\n",
      "torch.Size([2, 165]) torch.Size([79]) torch.Size([79])\n",
      "torch.Size([2, 20]) torch.Size([12]) torch.Size([12])\n",
      "torch.Size([2, 23]) torch.Size([13]) torch.Size([13])\n",
      "torch.Size([2, 289]) torch.Size([118]) torch.Size([118])\n",
      "torch.Size([2, 11]) torch.Size([7]) torch.Size([7])\n",
      "torch.Size([2, 164]) torch.Size([79]) torch.Size([79])\n",
      "torch.Size([2, 4]) torch.Size([4]) torch.Size([4])\n",
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 138]) torch.Size([71]) torch.Size([71])\n",
      "torch.Size([2, 10]) torch.Size([6]) torch.Size([6])\n",
      "torch.Size([2, 173]) torch.Size([81]) torch.Size([81])\n",
      "torch.Size([2, 149]) torch.Size([72]) torch.Size([72])\n",
      "torch.Size([2, 306]) torch.Size([124]) torch.Size([124])\n",
      "torch.Size([2, 283]) torch.Size([115]) torch.Size([115])\n",
      "torch.Size([2, 31]) torch.Size([15]) torch.Size([15])\n",
      "torch.Size([2, 50]) torch.Size([19]) torch.Size([19])\n",
      "torch.Size([2, 231]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 285]) torch.Size([116]) torch.Size([116])\n",
      "torch.Size([2, 202]) torch.Size([87]) torch.Size([87])\n",
      "torch.Size([2, 153]) torch.Size([72]) torch.Size([72])\n",
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 74]) torch.Size([33]) torch.Size([33])\n",
      "torch.Size([2, 185]) torch.Size([84]) torch.Size([84])\n",
      "torch.Size([2, 21]) torch.Size([13]) torch.Size([13])\n",
      "torch.Size([2, 141]) torch.Size([67]) torch.Size([67])\n",
      "torch.Size([2, 76]) torch.Size([34]) torch.Size([34])\n",
      "torch.Size([2, 19]) torch.Size([12]) torch.Size([12])\n",
      "torch.Size([2, 48]) torch.Size([18]) torch.Size([18])\n",
      "torch.Size([2, 131]) torch.Size([68]) torch.Size([68])\n",
      "torch.Size([2, 0]) torch.Size([2]) torch.Size([2])\n",
      "torch.Size([2, 325]) torch.Size([134]) torch.Size([134])\n",
      "torch.Size([2, 211]) torch.Size([90]) torch.Size([90])\n",
      "torch.Size([2, 4]) torch.Size([4]) torch.Size([4])\n",
      "torch.Size([2, 284]) torch.Size([115]) torch.Size([115])\n",
      "torch.Size([2, 19]) torch.Size([11]) torch.Size([11])\n",
      "torch.Size([2, 151]) torch.Size([74]) torch.Size([74])\n",
      "torch.Size([2, 327]) torch.Size([134]) torch.Size([134])\n",
      "torch.Size([2, 148]) torch.Size([70]) torch.Size([70])\n",
      "torch.Size([2, 192]) torch.Size([85]) torch.Size([85])\n",
      "torch.Size([2, 16]) torch.Size([8]) torch.Size([8])\n",
      "torch.Size([2, 46]) torch.Size([20]) torch.Size([20])\n",
      "torch.Size([2, 151]) torch.Size([73]) torch.Size([73])\n",
      "torch.Size([2, 332]) torch.Size([135]) torch.Size([135])\n",
      "torch.Size([2, 129]) torch.Size([67]) torch.Size([67])\n",
      "torch.Size([2, 23]) torch.Size([12]) torch.Size([12])\n",
      "torch.Size([2, 36]) torch.Size([21]) torch.Size([21])\n",
      "torch.Size([2, 233]) torch.Size([100]) torch.Size([100])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 174]) torch.Size([81]) torch.Size([81])\n",
      "torch.Size([2, 8]) torch.Size([5]) torch.Size([5])\n",
      "torch.Size([2, 0]) torch.Size([2]) torch.Size([2])\n",
      "torch.Size([2, 47]) torch.Size([20]) torch.Size([20])\n",
      "torch.Size([2, 31]) torch.Size([14]) torch.Size([14])\n",
      "torch.Size([2, 168]) torch.Size([79]) torch.Size([79])\n",
      "torch.Size([2, 239]) torch.Size([102]) torch.Size([102])\n",
      "torch.Size([2, 31]) torch.Size([15]) torch.Size([15])\n",
      "torch.Size([2, 34]) torch.Size([14]) torch.Size([14])\n",
      "torch.Size([2, 125]) torch.Size([64]) torch.Size([64])\n",
      "torch.Size([2, 196]) torch.Size([85]) torch.Size([85])\n",
      "torch.Size([2, 28]) torch.Size([12]) torch.Size([12])\n",
      "torch.Size([2, 326]) torch.Size([133]) torch.Size([133])\n",
      "torch.Size([2, 28]) torch.Size([12]) torch.Size([12])\n",
      "torch.Size([2, 173]) torch.Size([83]) torch.Size([83])\n",
      "torch.Size([2, 28]) torch.Size([12]) torch.Size([12])\n",
      "torch.Size([2, 186]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 16]) torch.Size([8]) torch.Size([8])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 21]) torch.Size([12]) torch.Size([12])\n",
      "torch.Size([2, 283]) torch.Size([115]) torch.Size([115])\n",
      "torch.Size([2, 162]) torch.Size([77]) torch.Size([77])\n",
      "torch.Size([2, 186]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 14]) torch.Size([7]) torch.Size([7])\n",
      "torch.Size([2, 33]) torch.Size([18]) torch.Size([18])\n",
      "torch.Size([2, 50]) torch.Size([21]) torch.Size([21])\n",
      "torch.Size([2, 165]) torch.Size([79]) torch.Size([79])\n",
      "torch.Size([2, 252]) torch.Size([105]) torch.Size([105])\n",
      "torch.Size([2, 165]) torch.Size([76]) torch.Size([76])\n",
      "torch.Size([2, 56]) torch.Size([22]) torch.Size([22])\n",
      "torch.Size([2, 183]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 66]) torch.Size([29]) torch.Size([29])\n",
      "torch.Size([2, 197]) torch.Size([86]) torch.Size([86])\n",
      "torch.Size([2, 11]) torch.Size([8]) torch.Size([8])\n",
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 11]) torch.Size([8]) torch.Size([8])\n",
      "torch.Size([2, 135]) torch.Size([71]) torch.Size([71])\n",
      "torch.Size([2, 22]) torch.Size([11]) torch.Size([11])\n",
      "torch.Size([2, 207]) torch.Size([89]) torch.Size([89])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 24]) torch.Size([10]) torch.Size([10])\n",
      "torch.Size([2, 70]) torch.Size([27]) torch.Size([27])\n",
      "torch.Size([2, 0]) torch.Size([2]) torch.Size([2])\n",
      "torch.Size([2, 27]) torch.Size([14]) torch.Size([14])\n",
      "torch.Size([2, 287]) torch.Size([116]) torch.Size([116])\n",
      "torch.Size([2, 323]) torch.Size([133]) torch.Size([133])\n",
      "torch.Size([2, 283]) torch.Size([115]) torch.Size([115])\n",
      "torch.Size([2, 231]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 14]) torch.Size([8]) torch.Size([8])\n",
      "torch.Size([2, 231]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 105]) torch.Size([59]) torch.Size([59])\n",
      "torch.Size([2, 40]) torch.Size([15]) torch.Size([15])\n",
      "torch.Size([2, 17]) torch.Size([10]) torch.Size([10])\n",
      "torch.Size([2, 308]) torch.Size([122]) torch.Size([122])\n",
      "torch.Size([2, 105]) torch.Size([58]) torch.Size([58])\n",
      "torch.Size([2, 5]) torch.Size([5]) torch.Size([5])\n",
      "torch.Size([2, 231]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 134]) torch.Size([69]) torch.Size([69])\n",
      "torch.Size([2, 186]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 36]) torch.Size([14]) torch.Size([14])\n",
      "torch.Size([2, 6]) torch.Size([5]) torch.Size([5])\n",
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 74]) torch.Size([33]) torch.Size([33])\n",
      "torch.Size([2, 231]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 142]) torch.Size([68]) torch.Size([68])\n",
      "torch.Size([2, 168]) torch.Size([80]) torch.Size([80])\n",
      "torch.Size([2, 232]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 125]) torch.Size([66]) torch.Size([66])\n",
      "torch.Size([2, 192]) torch.Size([82]) torch.Size([82])\n",
      "torch.Size([2, 127]) torch.Size([68]) torch.Size([68])\n",
      "torch.Size([2, 162]) torch.Size([77]) torch.Size([77])\n",
      "torch.Size([2, 0]) torch.Size([2]) torch.Size([2])\n",
      "torch.Size([2, 13]) torch.Size([7]) torch.Size([7])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 193]) torch.Size([85]) torch.Size([85])\n",
      "torch.Size([2, 19]) torch.Size([12]) torch.Size([12])\n",
      "torch.Size([2, 324]) torch.Size([133]) torch.Size([133])\n",
      "torch.Size([2, 192]) torch.Size([84]) torch.Size([84])\n",
      "torch.Size([2, 322]) torch.Size([133]) torch.Size([133])\n",
      "torch.Size([2, 114]) torch.Size([64]) torch.Size([64])\n",
      "torch.Size([2, 25]) torch.Size([11]) torch.Size([11])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 29]) torch.Size([13]) torch.Size([13])\n",
      "torch.Size([2, 38]) torch.Size([18]) torch.Size([18])\n",
      "torch.Size([2, 12]) torch.Size([9]) torch.Size([9])\n",
      "torch.Size([2, 2]) torch.Size([3]) torch.Size([3])\n",
      "torch.Size([2, 231]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 30]) torch.Size([13]) torch.Size([13])\n",
      "torch.Size([2, 283]) torch.Size([115]) torch.Size([115])\n",
      "torch.Size([2, 283]) torch.Size([115]) torch.Size([115])\n",
      "torch.Size([2, 5]) torch.Size([5]) torch.Size([5])\n",
      "torch.Size([2, 159]) torch.Size([79]) torch.Size([79])\n",
      "torch.Size([2, 203]) torch.Size([90]) torch.Size([90])\n",
      "torch.Size([2, 0]) torch.Size([2]) torch.Size([2])\n",
      "torch.Size([2, 286]) torch.Size([116]) torch.Size([116])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 116]) torch.Size([63]) torch.Size([63])\n",
      "torch.Size([2, 143]) torch.Size([68]) torch.Size([68])\n",
      "torch.Size([2, 1]) torch.Size([3]) torch.Size([3])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 45]) torch.Size([19]) torch.Size([19])\n",
      "torch.Size([2, 46]) torch.Size([20]) torch.Size([20])\n",
      "torch.Size([2, 291]) torch.Size([118]) torch.Size([118])\n",
      "torch.Size([2, 323]) torch.Size([133]) torch.Size([133])\n",
      "torch.Size([2, 31]) torch.Size([18]) torch.Size([18])\n",
      "torch.Size([2, 5]) torch.Size([5]) torch.Size([5])\n",
      "torch.Size([2, 323]) torch.Size([133]) torch.Size([133])\n",
      "torch.Size([2, 231]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 284]) torch.Size([115]) torch.Size([115])\n",
      "torch.Size([2, 4]) torch.Size([5]) torch.Size([5])\n",
      "torch.Size([2, 164]) torch.Size([79]) torch.Size([79])\n",
      "torch.Size([2, 18]) torch.Size([11]) torch.Size([11])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 167]) torch.Size([73]) torch.Size([73])\n",
      "torch.Size([2, 39]) torch.Size([15]) torch.Size([15])\n",
      "torch.Size([2, 175]) torch.Size([83]) torch.Size([83])\n",
      "torch.Size([2, 19]) torch.Size([9]) torch.Size([9])\n",
      "torch.Size([2, 27]) torch.Size([12]) torch.Size([12])\n",
      "torch.Size([2, 8]) torch.Size([5]) torch.Size([5])\n",
      "torch.Size([2, 186]) torch.Size([89]) torch.Size([89])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 49]) torch.Size([20]) torch.Size([20])\n",
      "torch.Size([2, 144]) torch.Size([69]) torch.Size([69])\n",
      "torch.Size([2, 283]) torch.Size([115]) torch.Size([115])\n",
      "torch.Size([2, 190]) torch.Size([89]) torch.Size([89])\n",
      "torch.Size([2, 185]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 39]) torch.Size([17]) torch.Size([17])\n",
      "torch.Size([2, 142]) torch.Size([73]) torch.Size([73])\n",
      "torch.Size([2, 10]) torch.Size([7]) torch.Size([7])\n",
      "torch.Size([2, 75]) torch.Size([31]) torch.Size([31])\n",
      "torch.Size([2, 20]) torch.Size([9]) torch.Size([9])\n",
      "torch.Size([2, 232]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 112]) torch.Size([62]) torch.Size([62])\n",
      "torch.Size([2, 18]) torch.Size([9]) torch.Size([9])\n",
      "torch.Size([2, 17]) torch.Size([10]) torch.Size([10])\n",
      "torch.Size([2, 328]) torch.Size([134]) torch.Size([134])\n",
      "torch.Size([2, 324]) torch.Size([133]) torch.Size([133])\n",
      "torch.Size([2, 191]) torch.Size([82]) torch.Size([82])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 162]) torch.Size([77]) torch.Size([77])\n",
      "torch.Size([2, 30]) torch.Size([14]) torch.Size([14])\n",
      "torch.Size([2, 17]) torch.Size([12]) torch.Size([12])\n",
      "torch.Size([2, 283]) torch.Size([115]) torch.Size([115])\n",
      "torch.Size([2, 44]) torch.Size([17]) torch.Size([17])\n",
      "torch.Size([2, 202]) torch.Size([87]) torch.Size([87])\n",
      "torch.Size([2, 11]) torch.Size([7]) torch.Size([7])\n",
      "torch.Size([2, 208]) torch.Size([89]) torch.Size([89])\n",
      "torch.Size([2, 10]) torch.Size([6]) torch.Size([6])\n",
      "torch.Size([2, 153]) torch.Size([73]) torch.Size([73])\n",
      "torch.Size([2, 323]) torch.Size([133]) torch.Size([133])\n",
      "torch.Size([2, 142]) torch.Size([68]) torch.Size([68])\n",
      "torch.Size([2, 39]) torch.Size([15]) torch.Size([15])\n",
      "torch.Size([2, 232]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 107]) torch.Size([61]) torch.Size([61])\n",
      "torch.Size([2, 232]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 31]) torch.Size([12]) torch.Size([12])\n",
      "torch.Size([2, 151]) torch.Size([74]) torch.Size([74])\n",
      "torch.Size([2, 24]) torch.Size([13]) torch.Size([13])\n",
      "torch.Size([2, 142]) torch.Size([72]) torch.Size([72])\n",
      "torch.Size([2, 35]) torch.Size([18]) torch.Size([18])\n",
      "torch.Size([2, 231]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 115]) torch.Size([64]) torch.Size([64])\n",
      "torch.Size([2, 131]) torch.Size([66]) torch.Size([66])\n",
      "torch.Size([2, 186]) torch.Size([88]) torch.Size([88])\n",
      "torch.Size([2, 231]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 28]) torch.Size([14]) torch.Size([14])\n",
      "torch.Size([2, 47]) torch.Size([20]) torch.Size([20])\n",
      "torch.Size([2, 10]) torch.Size([6]) torch.Size([6])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 22]) torch.Size([10]) torch.Size([10])\n",
      "torch.Size([2, 112]) torch.Size([62]) torch.Size([62])\n",
      "torch.Size([2, 12]) torch.Size([8]) torch.Size([8])\n",
      "torch.Size([2, 2]) torch.Size([3]) torch.Size([3])\n",
      "torch.Size([2, 2]) torch.Size([3]) torch.Size([3])\n",
      "torch.Size([2, 321]) torch.Size([132]) torch.Size([132])\n",
      "torch.Size([2, 10]) torch.Size([7]) torch.Size([7])\n",
      "torch.Size([2, 130]) torch.Size([66]) torch.Size([66])\n",
      "torch.Size([2, 231]) torch.Size([99]) torch.Size([99])\n",
      "torch.Size([2, 37]) torch.Size([17]) torch.Size([17])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-16a48ea52a09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mMyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_hops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hw2_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mMyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_hops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hw2_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_hops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hw2_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-261-91344f1f114b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_hops, root, split)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_hops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/torch_geometric/data/in_memory_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     52\u001b[0m                  pre_filter=None):\n\u001b[1;32m     53\u001b[0m         super(InMemoryDataset, self).__init__(root, transform, pre_transform,\n\u001b[0;32m---> 54\u001b[0;31m                                               pre_filter)\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_list__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'process'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/torch_geometric/data/dataset.py\u001b[0m in \u001b[0;36m_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pre_transform.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-261-91344f1f114b>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         train_pos_list = self.extract_enclosing_subgraphs(\n\u001b[0;32m---> 70\u001b[0;31m             train_pos_edge, train_pos_edge, 1, num_nodes=num_nodes)\n\u001b[0m\u001b[1;32m     71\u001b[0m         train_neg_list = self.extract_enclosing_subgraphs(\n\u001b[1;32m     72\u001b[0m             train_neg_edge, train_pos_edge, 0, num_nodes=num_nodes)\n",
      "\u001b[0;32m<ipython-input-261-91344f1f114b>\u001b[0m in \u001b[0;36mextract_enclosing_subgraphs\u001b[0;34m(self, link_index, edge_index, y, num_nodes, scale)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;31m# Calculate node labeling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 z = self.drnl_node_labeling(sub_edge_index, src, dst,\n\u001b[0;32m--> 123\u001b[0;31m                                             num_nodes=sub_nodes.size(0))\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 data = Data(x=self.data.x[sub_nodes], z=z,\n",
      "\u001b[0;32m<ipython-input-261-91344f1f114b>\u001b[0m in \u001b[0;36mdrnl_node_labeling\u001b[0;34m(self, edge_index, src, dst, num_nodes)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0madj_wo_dst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         dist2src = shortest_path(adj_wo_dst, directed=False, unweighted=True,\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0missequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;31m# row is slice, col is sequence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m                 \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m        \u001b[0;31m# [1:2,[1,2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m                 \u001b[0msliced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'T'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'H'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(self, axes, copy)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcsc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsc_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         return csc_matrix((self.data, self.indices,\n\u001b[0;32m--> 141\u001b[0;31m                            self.indptr), shape=(N, M), copy=copy)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mtranspose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mcheck_format\u001b[0;34m(self, full_check)\u001b[0m\n\u001b[1;32m    160\u001b[0m             raise ValueError(\"index pointer size (%d) should be (%d)\" %\n\u001b[1;32m    161\u001b[0m                                 (len(self.indptr), major_dim + 1))\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"index pointer should start with 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset =  MyDataset(num_hops=2, root=os.path.join(os.getcwd(), \"hw2_data\", dataset), split=\"train\")\n",
    "# val_dataset =  MyDataset(num_hops=2, root=os.path.join(os.getcwd(), \"hw2_data\", dataset), split=\"valid\")\n",
    "test_dataset = MyDataset(num_hops=2, root=os.path.join(os.getcwd(), \"hw2_data\", dataset), split=\"test\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "packed-mailing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyDataset(11106)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "copyrighted-ordinary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 53], x=[24, 3749], y=[1], z=[24])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "later-policy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyDataset(1868)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "subjective-juvenile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use a new optimizer\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model, optimizer = load_checkpoint(os.path.join(save, \"{}.pth\".format(date_time)), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "democratic-modern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save Model\n",
      "Epoch: 01, Loss: 0.6766, Val: 0.7851\n",
      "\n",
      "Save Model\n",
      "Epoch: 02, Loss: 0.5205, Val: 0.8344\n",
      "\n",
      "Save Model\n",
      "Epoch: 03, Loss: 0.4566, Val: 0.8615\n",
      "\n",
      "Save Model\n",
      "Epoch: 04, Loss: 0.3857, Val: 0.8800\n",
      "\n",
      "Save Model\n",
      "Epoch: 05, Loss: 0.3166, Val: 0.8926\n",
      "\n",
      "Save Model\n",
      "Epoch: 06, Loss: 0.2695, Val: 0.9021\n",
      "\n",
      "Save Model\n",
      "Epoch: 07, Loss: 0.2257, Val: 0.9063\n",
      "\n",
      "Save Model\n",
      "Epoch: 08, Loss: 0.2010, Val: 0.9121\n",
      "\n",
      "Save Model\n",
      "Epoch: 09, Loss: 0.1841, Val: 0.9172\n",
      "\n",
      "Save Model\n",
      "Epoch: 10, Loss: 0.1692, Val: 0.9199\n",
      "\n",
      "Save Model\n",
      "Epoch: 11, Loss: 0.1567, Val: 0.9206\n",
      "\n",
      "Save Model\n",
      "Epoch: 12, Loss: 0.1508, Val: 0.9256\n",
      "\n",
      "Save Model\n",
      "Epoch: 13, Loss: 0.1385, Val: 0.9285\n",
      "\n",
      "Save Model\n",
      "Epoch: 14, Loss: 0.1300, Val: 0.9308\n",
      "Epoch: 15, Loss: 0.1193, Val: 0.9302\n",
      "\n",
      "Save Model\n",
      "Epoch: 16, Loss: 0.1157, Val: 0.9342\n",
      "Epoch: 17, Loss: 0.1096, Val: 0.9338\n",
      "Epoch: 18, Loss: 0.1020, Val: 0.9328\n",
      "Epoch: 19, Loss: 0.0998, Val: 0.9336\n",
      "\n",
      "Save Model\n",
      "Epoch: 20, Loss: 0.0927, Val: 0.9362\n",
      "Epoch: 21, Loss: 0.0967, Val: 0.9356\n",
      "Epoch: 22, Loss: 0.0883, Val: 0.9362\n",
      "\n",
      "Save Model\n",
      "Epoch: 23, Loss: 0.0832, Val: 0.9388\n",
      "Epoch: 24, Loss: 0.0775, Val: 0.9382\n",
      "\n",
      "Save Model\n",
      "Epoch: 25, Loss: 0.0789, Val: 0.9391\n",
      "\n",
      "Save Model\n",
      "Epoch: 26, Loss: 0.0758, Val: 0.9400\n",
      "Epoch: 27, Loss: 0.0736, Val: 0.9381\n",
      "Epoch: 28, Loss: 0.0699, Val: 0.9385\n",
      "\n",
      "Save Model\n",
      "Epoch: 29, Loss: 0.0693, Val: 0.9416\n",
      "Epoch: 30, Loss: 0.0614, Val: 0.9408\n",
      "\n",
      "Save Model\n",
      "Epoch: 31, Loss: 0.0624, Val: 0.9419\n",
      "\n",
      "Save Model\n",
      "Epoch: 32, Loss: 0.0664, Val: 0.9420\n",
      "\n",
      "Save Model\n",
      "Epoch: 33, Loss: 0.0637, Val: 0.9435\n",
      "\n",
      "Save Model\n",
      "Epoch: 34, Loss: 0.0578, Val: 0.9436\n",
      "\n",
      "Save Model\n",
      "Epoch: 35, Loss: 0.0527, Val: 0.9436\n",
      "Epoch: 36, Loss: 0.0506, Val: 0.9433\n",
      "Epoch: 37, Loss: 0.0555, Val: 0.9416\n",
      "Epoch: 38, Loss: 0.0520, Val: 0.9426\n",
      "Epoch: 39, Loss: 0.0480, Val: 0.9429\n",
      "Epoch: 40, Loss: 0.0469, Val: 0.9418\n",
      "Epoch: 41, Loss: 0.0449, Val: 0.9427\n",
      "Epoch: 42, Loss: 0.0417, Val: 0.9430\n",
      "Epoch: 43, Loss: 0.0455, Val: 0.9425\n",
      "Epoch: 44, Loss: 0.0404, Val: 0.9419\n",
      "Epoch: 45, Loss: 0.0431, Val: 0.9425\n",
      "Epoch: 46, Loss: 0.0379, Val: 0.9423\n",
      "Epoch: 47, Loss: 0.0348, Val: 0.9435\n",
      "\n",
      "Save Model\n",
      "Epoch: 48, Loss: 0.0371, Val: 0.9445\n",
      "\n",
      "Save Model\n",
      "Epoch: 49, Loss: 0.0346, Val: 0.9455\n",
      "Epoch: 50, Loss: 0.0343, Val: 0.9453\n",
      "\n",
      "Save Model\n",
      "Epoch: 51, Loss: 0.0363, Val: 0.9467\n",
      "Epoch: 52, Loss: 0.0374, Val: 0.9453\n",
      "\n",
      "Save Model\n",
      "Epoch: 53, Loss: 0.0356, Val: 0.9469\n",
      "Epoch: 54, Loss: 0.0290, Val: 0.9453\n",
      "Epoch: 55, Loss: 0.0261, Val: 0.9451\n",
      "Epoch: 56, Loss: 0.0287, Val: 0.9444\n",
      "Epoch: 57, Loss: 0.0259, Val: 0.9453\n",
      "Epoch: 58, Loss: 0.0290, Val: 0.9466\n",
      "Epoch: 59, Loss: 0.0245, Val: 0.9467\n",
      "\n",
      "Save Model\n",
      "Epoch: 60, Loss: 0.0317, Val: 0.9471\n",
      "Epoch: 61, Loss: 0.0295, Val: 0.9437\n",
      "Epoch: 62, Loss: 0.0331, Val: 0.9446\n",
      "\n",
      "Save Model\n",
      "Epoch: 63, Loss: 0.0303, Val: 0.9471\n",
      "Epoch: 64, Loss: 0.0255, Val: 0.9469\n",
      "\n",
      "Save Model\n",
      "Epoch: 65, Loss: 0.0280, Val: 0.9479\n",
      "Epoch: 66, Loss: 0.0218, Val: 0.9473\n",
      "Epoch: 67, Loss: 0.0209, Val: 0.9464\n",
      "Epoch: 68, Loss: 0.0184, Val: 0.9468\n",
      "\n",
      "Save Model\n",
      "Epoch: 69, Loss: 0.0222, Val: 0.9481\n",
      "Epoch: 70, Loss: 0.0247, Val: 0.9462\n",
      "Epoch: 71, Loss: 0.0248, Val: 0.9457\n",
      "Epoch: 72, Loss: 0.0213, Val: 0.9474\n",
      "Epoch: 73, Loss: 0.0253, Val: 0.9473\n",
      "Epoch: 74, Loss: 0.0153, Val: 0.9475\n",
      "Epoch: 75, Loss: 0.0161, Val: 0.9476\n",
      "Epoch: 76, Loss: 0.0197, Val: 0.9478\n",
      "\n",
      "Save Model\n",
      "Epoch: 77, Loss: 0.0185, Val: 0.9497\n",
      "Epoch: 78, Loss: 0.0221, Val: 0.9468\n",
      "Epoch: 79, Loss: 0.0210, Val: 0.9467\n",
      "Epoch: 80, Loss: 0.0154, Val: 0.9476\n",
      "Epoch: 81, Loss: 0.0181, Val: 0.9468\n",
      "Epoch: 82, Loss: 0.0211, Val: 0.9468\n",
      "Epoch: 83, Loss: 0.0174, Val: 0.9485\n",
      "Epoch: 84, Loss: 0.0180, Val: 0.9488\n",
      "Epoch: 85, Loss: 0.0145, Val: 0.9497\n",
      "\n",
      "Save Model\n",
      "Epoch: 86, Loss: 0.0159, Val: 0.9499\n",
      "Epoch: 87, Loss: 0.0186, Val: 0.9464\n",
      "Epoch: 88, Loss: 0.0197, Val: 0.9489\n",
      "Epoch: 89, Loss: 0.0188, Val: 0.9471\n",
      "Epoch: 90, Loss: 0.0191, Val: 0.9461\n",
      "Epoch: 91, Loss: 0.0208, Val: 0.9434\n",
      "Epoch: 92, Loss: 0.0176, Val: 0.9465\n",
      "Epoch: 93, Loss: 0.0103, Val: 0.9467\n",
      "Epoch: 94, Loss: 0.0089, Val: 0.9460\n",
      "Epoch: 95, Loss: 0.0135, Val: 0.9472\n",
      "Epoch: 96, Loss: 0.0231, Val: 0.9460\n",
      "Epoch: 97, Loss: 0.0156, Val: 0.9469\n",
      "Epoch: 98, Loss: 0.0170, Val: 0.9451\n",
      "Epoch: 99, Loss: 0.0171, Val: 0.9468\n",
      "Epoch: 100, Loss: 0.0150, Val: 0.9480\n"
     ]
    }
   ],
   "source": [
    "best_val_auc = test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train(train_loader)\n",
    "    val_auc = test(val_loader)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        \n",
    "\n",
    "        checkpoint = {\n",
    "            'model_stat': model.state_dict(),\n",
    "            'optimizer_stat': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, os.path.join(save, \n",
    "                                            \"{}.pth\".format(date_time)))\n",
    "        print(\"\\nSave Model\")\n",
    "        \n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "white-wright",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained finded\n"
     ]
    }
   ],
   "source": [
    "model, optimizer = load_checkpoint(os.path.join(save, \"{}.pth\".format(date_time)), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "skilled-hunger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred = pd.read_csv(os.path.join(os.getcwd(), \"hw2_data\", dataset, \"raw\", \"test.csv\"))\n",
    "\n",
    "test_pred[\"prob\"] = np.nan\n",
    "test_pred.loc[(test_pred[\"from\"] == test_pred[\"to\"]), [\"prob\"]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "fitting-functionality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.   , 1.   , 1.   , ..., 0.   , 0.999, 1.   ], dtype=float32)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = predict(test_loader)\n",
    "pred = np.concatenate(pred)\n",
    "pred = np.round(pred,3)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "advised-polyester",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for row in range(start, len(test_pred)):\n",
    "    if np.isnan(test_pred.at[row, \"prob\"]):\n",
    "        test_pred.at[row, \"prob\"] = pred[i]\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "proof-angle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E3064</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E298</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E3512</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E5670</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E5005</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>E9179</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>E5003</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>E5081</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>E4705</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>E1012</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1886 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id   prob\n",
       "0     E3064  1.000\n",
       "1      E298  1.000\n",
       "2     E3512  1.000\n",
       "3     E5670  1.000\n",
       "4     E5005  0.066\n",
       "...     ...    ...\n",
       "1881  E9179  0.015\n",
       "1882  E5003  1.000\n",
       "1883  E5081  0.000\n",
       "1884  E4705  0.999\n",
       "1885  E1012  1.000\n",
       "\n",
       "[1886 rows x 2 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload = test_pred[[\"id\", \"prob\"]]\n",
    "upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "helpful-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.to_csv(os.path.join(save, \"{}.csv\".format(date_time)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "bibliographic-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload.to_csv(os.path.join(save, \"upload.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-pocket",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
