{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper: Link Prediction Based on Graph Neural Networks (NeurIPS 2018)\n",
    "# Example: https://github.com/rusty1s/pytorch_geometric/blob/99a496e077a4d41417c7d927df7730fd984004b9/examples/seal_link_pred.py#L90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "large-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os.path as osp\n",
    "from itertools import chain\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.nn import ModuleList, Linear, Conv1d, MaxPool1d\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv, global_sort_pool\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader, Dataset\n",
    "from torch_geometric.utils import (negative_sampling, add_self_loops,\n",
    "                                   train_test_split_edges, k_hop_subgraph,\n",
    "                                   to_scipy_sparse_matrix, to_undirected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-forum",
   "metadata": {},
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quick-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(x):\n",
    "    if not isinstance(x, (tuple, list)):\n",
    "        x = [x]\n",
    "    return x\n",
    "\n",
    "\n",
    "def files_exist(files):\n",
    "    return len(files) != 0 and all(osp.exists(f) for f in files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spatial-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEALDataset(InMemoryDataset):\n",
    "    def __init__(self, dataset, num_hops, split='train'):\n",
    "        self.data = dataset[0]\n",
    "        self.num_hops = num_hops\n",
    "        super(SEALDataset, self).__init__(dataset.root)\n",
    "        index = ['train', 'val', 'test'].index(split)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[index])\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['SEAL_train_data.pt', 'SEAL_val_data.pt', 'SEAL_test_data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        random.seed(12345)\n",
    "        torch.manual_seed(12345)\n",
    "\n",
    "        data = train_test_split_edges(self.data)\n",
    "\n",
    "        edge_index, _ = add_self_loops(data.train_pos_edge_index)\n",
    "        \n",
    "        data.train_neg_edge_index = negative_sampling(\n",
    "            edge_index, num_nodes=data.num_nodes,\n",
    "            num_neg_samples=data.train_pos_edge_index.size(1))\n",
    "\n",
    "        self.__max_z__ = 0\n",
    "\n",
    "        # Collect a list of subgraphs for training, validation and test.\n",
    "        train_pos_list = self.extract_enclosing_subgraphs(\n",
    "            data.train_pos_edge_index, data.train_pos_edge_index, 1)\n",
    "        train_neg_list = self.extract_enclosing_subgraphs(\n",
    "            data.train_neg_edge_index, data.train_pos_edge_index, 0)\n",
    "\n",
    "        val_pos_list = self.extract_enclosing_subgraphs(\n",
    "            data.val_pos_edge_index, data.train_pos_edge_index, 1)\n",
    "        val_neg_list = self.extract_enclosing_subgraphs(\n",
    "            data.val_neg_edge_index, data.train_pos_edge_index, 0)\n",
    "\n",
    "        test_pos_list = self.extract_enclosing_subgraphs(\n",
    "            data.test_pos_edge_index, data.train_pos_edge_index, 1)\n",
    "        test_neg_list = self.extract_enclosing_subgraphs(\n",
    "            data.test_neg_edge_index, data.train_pos_edge_index, 0)\n",
    "\n",
    "        # Convert labels to one-hot features.\n",
    "        for data in chain(train_pos_list, train_neg_list, val_pos_list,\n",
    "                          val_neg_list, test_pos_list, test_neg_list):\n",
    "            data.x = F.one_hot(data.z, self.__max_z__ + 1).to(torch.float)\n",
    "\n",
    "            \n",
    "        torch.save(self.collate(train_pos_list + train_neg_list),\n",
    "                   self.processed_paths[0])\n",
    "        torch.save(self.collate(val_pos_list + val_neg_list),\n",
    "                   self.processed_paths[1])\n",
    "        torch.save(self.collate(test_pos_list + test_neg_list),\n",
    "                   self.processed_paths[2])\n",
    "\n",
    "    def extract_enclosing_subgraphs(self, link_index, edge_index, y):\n",
    "        data_list = []\n",
    "        for src, dst in link_index.t().tolist():\n",
    "            sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
    "                [src, dst], self.num_hops, edge_index, relabel_nodes=True)\n",
    "            src, dst = mapping.tolist()\n",
    "\n",
    "            # Remove target link from the subgraph.\n",
    "            mask1 = (sub_edge_index[0] != src) | (sub_edge_index[1] != dst)\n",
    "            mask2 = (sub_edge_index[0] != dst) | (sub_edge_index[1] != src)\n",
    "            sub_edge_index = sub_edge_index[:, mask1 & mask2]\n",
    "\n",
    "            # Calculate node labeling.\n",
    "            z = self.drnl_node_labeling(sub_edge_index, src, dst,\n",
    "                                        num_nodes=sub_nodes.size(0))\n",
    "\n",
    "            data = Data(x=self.data.x[sub_nodes], z=z,\n",
    "                        edge_index=sub_edge_index, y=y)\n",
    "        \n",
    "            data_list.append(data)\n",
    "\n",
    "        return data_list\n",
    "\n",
    "    def drnl_node_labeling(self, edge_index, src, dst, num_nodes=None):\n",
    "        # Double-radius node labeling (DRNL).\n",
    "        src, dst = (dst, src) if src > dst else (src, dst)\n",
    "        adj = to_scipy_sparse_matrix(edge_index, num_nodes=num_nodes).tocsr()\n",
    "\n",
    "        idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
    "        adj_wo_src = adj[idx, :][:, idx]\n",
    "\n",
    "        idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
    "        adj_wo_dst = adj[idx, :][:, idx]\n",
    "\n",
    "        dist2src = shortest_path(adj_wo_dst, directed=False, unweighted=True,\n",
    "                                 indices=src)\n",
    "        dist2src = np.insert(dist2src, dst, 0, axis=0)\n",
    "        dist2src = torch.from_numpy(dist2src)\n",
    "\n",
    "        dist2dst = shortest_path(adj_wo_src, directed=False, unweighted=True,\n",
    "                                 indices=dst - 1)\n",
    "        dist2dst = np.insert(dist2dst, src, 0, axis=0)\n",
    "        dist2dst = torch.from_numpy(dist2dst)\n",
    "\n",
    "        dist = dist2src + dist2dst\n",
    "        dist_over_2, dist_mod_2 = dist // 2, dist % 2\n",
    "\n",
    "        z = 1 + torch.min(dist2src, dist2dst)\n",
    "        z += dist_over_2 * (dist_over_2 + dist_mod_2 - 1)\n",
    "        z[src] = 1.\n",
    "        z[dst] = 1.\n",
    "        z[torch.isnan(z)] = 0.\n",
    "\n",
    "        self.__max_z__ = max(int(z.max()), self.__max_z__)\n",
    "\n",
    "        return z.to(torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "available-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(InMemoryDataset):\n",
    "    \n",
    "    def __init__(self, num_hops, root=None, split=\"train\"):\n",
    "        \n",
    "        self.num_hops = num_hops\n",
    "        super().__init__(root=root)\n",
    "        \n",
    "        index = ['train', 'valid'].index(split)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[index])\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):  \n",
    "        return [\"train.csv\"]\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['SEAL_data_0.pt', 'SEAL_data_1.pt']\n",
    "    \n",
    "    def process(self):\n",
    "        # Read node features\n",
    "        content = pd.read_csv(os.path.join(self.raw_dir, \"content.csv\"), delimiter=\"\\t\", header=None)\n",
    "        content = content.sort_values(by=[0]).loc[:, 1:].to_numpy()\n",
    "        content = torch.from_numpy(content)\n",
    "        num_nodes = content.size(0)\n",
    "\n",
    "        # Read edge list\n",
    "        train = pd.read_csv(os.path.join(self.raw_dir, \"train.csv\"))\n",
    "\n",
    "        train_pos = train[ train[\"label\"] == 1]\n",
    "        train_neg = train[ train[\"label\"] == 0]\n",
    "\n",
    "        follower_pos = train_pos[\"from\"].to_numpy().tolist()\n",
    "        followee_pos = train_pos[\"to\"].to_numpy().tolist()\n",
    "        train_pos_edge = torch.tensor([follower_pos, followee_pos], dtype=torch.long)\n",
    "        train_pos_edge = to_undirected(train_pos_edge)\n",
    "#         train_pos_edge = add_self_loops(train_pos_edge)[0]\n",
    "\n",
    "        self.data = Data(x=content, edge_index=train_pos_edge, num_nodes=num_nodes)\n",
    "\n",
    "        train_pos_edge = train_pos_edge.t()\n",
    "\n",
    "        follower_neg = train_neg[\"from\"].to_numpy().tolist()\n",
    "        followee_neg = train_neg[\"to\"].to_numpy().tolist()\n",
    "        train_neg_edge = torch.tensor([follower_neg, followee_neg], dtype=torch.long)\n",
    "        train_neg_edge = to_undirected(train_neg_edge)\n",
    "        \n",
    "#         neg_data = Data(edge_index=train_neg_edge, num_nodes=num_nodes)\n",
    "#         train_neg_edge = add_self_loops(neg_data.edge_index)[0]\n",
    "        \n",
    "        train_neg_edge = train_neg_edge.t()\n",
    "\n",
    "        train_pos_edge, valid_pos_edge = train_test_split(train_pos_edge, shuffle=True)\n",
    "        train_neg_edge, valid_neg_edge = train_test_split(train_neg_edge, shuffle=True)\n",
    "\n",
    "        train_pos_edge = train_pos_edge.t()\n",
    "        valid_pos_edge = valid_pos_edge.t()\n",
    "        train_neg_edge = train_neg_edge.t()\n",
    "        valid_neg_edge = valid_neg_edge.t()\n",
    "\n",
    "\n",
    "        self.__max_z__ = 0\n",
    "\n",
    "\n",
    "        train_pos_list = self.extract_enclosing_subgraphs(\n",
    "            train_pos_edge, train_pos_edge, 1)\n",
    "        train_neg_list = self.extract_enclosing_subgraphs(\n",
    "            train_neg_edge, train_pos_edge, 0)\n",
    "    \n",
    "\n",
    "        val_pos_list = self.extract_enclosing_subgraphs(\n",
    "            valid_pos_edge, train_pos_edge, 1)\n",
    "        val_neg_list = self.extract_enclosing_subgraphs(\n",
    "            valid_neg_edge, train_pos_edge, 0)\n",
    "\n",
    "\n",
    "        # Convert labels to one-hot features.\n",
    "        for data in chain(train_pos_list, train_neg_list, \n",
    "                          val_pos_list, val_neg_list):\n",
    "            z = F.one_hot(data.z, self.__max_z__ + 1).to(torch.float)\n",
    "            data.x = torch.cat([z, data.x], 1)\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "        torch.save(self.collate(train_pos_list + train_neg_list),\n",
    "                   self.processed_paths[0])\n",
    "        torch.save(self.collate(val_pos_list + val_neg_list),\n",
    "                   self.processed_paths[1])\n",
    "\n",
    "\n",
    "#         if self.pre_filter is not None and not self.pre_filter(data):\n",
    "#             continue\n",
    "\n",
    "#         if self.pre_transform is not None:\n",
    "#             data = self.pre_transform(data)\n",
    "\n",
    "\n",
    "#         torch.save(self.collate(train_pos_list + train_neg_list),\n",
    "#                    self.processed_paths[0])\n",
    "#         torch.save(self.collate(val_pos_list + val_neg_list),\n",
    "#                    self.processed_paths[1])\n",
    "\n",
    "    \n",
    "#     def len(self):\n",
    "#         return len(self.processed_file_names)\n",
    "    \n",
    "    \n",
    "    def extract_enclosing_subgraphs(self, link_index, edge_index, y):\n",
    "        data_list = []\n",
    "        for src, dst in link_index.t().tolist():\n",
    "            sub_nodes, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
    "                [src, dst], self.num_hops, edge_index, relabel_nodes=True)\n",
    "            src, dst = mapping.tolist()\n",
    "\n",
    "            # Remove target link from the subgraph.\n",
    "            mask1 = (sub_edge_index[0] != src) | (sub_edge_index[1] != dst)\n",
    "            mask2 = (sub_edge_index[0] != dst) | (sub_edge_index[1] != src)\n",
    "            sub_edge_index = sub_edge_index[:, mask1 & mask2]\n",
    "\n",
    "            # Calculate node labeling.\n",
    "            z = self.drnl_node_labeling(sub_edge_index, src, dst,\n",
    "                                        num_nodes=sub_nodes.size(0))\n",
    "\n",
    "            data = Data(x=self.data.x[sub_nodes], z=z,\n",
    "                        edge_index=sub_edge_index, y=y)\n",
    "            data_list.append(data)\n",
    "\n",
    "        return data_list\n",
    "\n",
    "    def drnl_node_labeling(self, edge_index, src, dst, num_nodes=None):\n",
    "        # Double-radius node labeling (DRNL).\n",
    "        src, dst = (dst, src) if src > dst else (src, dst)\n",
    "        adj = to_scipy_sparse_matrix(edge_index, num_nodes=num_nodes).tocsr()\n",
    "\n",
    "        idx = list(range(src)) + list(range(src + 1, adj.shape[0]))\n",
    "        adj_wo_src = adj[idx, :][:, idx]\n",
    "\n",
    "        idx = list(range(dst)) + list(range(dst + 1, adj.shape[0]))\n",
    "        adj_wo_dst = adj[idx, :][:, idx]\n",
    "        \n",
    "#         print(src, adj_wo_dst.shape)\n",
    "#         print(adj_wo_dst[src])\n",
    "        \n",
    "\n",
    "        dist2src = shortest_path(adj_wo_dst, directed=False, unweighted=True,\n",
    "                                 indices=src)\n",
    "        dist2src = np.insert(dist2src, dst, 0, axis=0)\n",
    "        dist2src = torch.from_numpy(dist2src)\n",
    "\n",
    "        dist2dst = shortest_path(adj_wo_src, directed=False, unweighted=True,\n",
    "                                 indices=dst - 1)\n",
    "        dist2dst = np.insert(dist2dst, src, 0, axis=0)\n",
    "        dist2dst = torch.from_numpy(dist2dst)\n",
    "\n",
    "        dist = dist2src + dist2dst\n",
    "        dist_over_2, dist_mod_2 = dist // 2, dist % 2\n",
    "\n",
    "        z = 1 + torch.min(dist2src, dist2dst)\n",
    "        z += dist_over_2 * (dist_over_2 + dist_mod_2 - 1)\n",
    "        z[src] = 1.\n",
    "        z[dst] = 1.\n",
    "        z[torch.isnan(z)] = 0.\n",
    "\n",
    "        self.__max_z__ = max(int(z.max()), self.__max_z__)\n",
    "\n",
    "        return z.to(torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-prerequisite",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "traditional-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGCNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_layers, GNN=GCNConv, k=0.6):\n",
    "        super(DGCNN, self).__init__()\n",
    "\n",
    "        if k < 1:  # Transform percentile to number.\n",
    "            num_nodes = sorted([data.num_nodes for data in train_dataset])\n",
    "            k = num_nodes[int(math.ceil(k * len(num_nodes))) - 1]\n",
    "            k = max(10, k)\n",
    "        self.k = int(k)\n",
    "\n",
    "        self.convs = ModuleList()\n",
    "        self.convs.append(GNN(train_dataset.num_features, hidden_channels))\n",
    "        for i in range(0, num_layers - 1):\n",
    "            self.convs.append(GNN(hidden_channels, hidden_channels))\n",
    "        self.convs.append(GNN(hidden_channels, 1))\n",
    "\n",
    "        conv1d_channels = [16, 32]\n",
    "        total_latent_dim = hidden_channels * num_layers + 1\n",
    "        conv1d_kws = [total_latent_dim, 5]\n",
    "        self.conv1 = Conv1d(1, conv1d_channels[0], conv1d_kws[0],\n",
    "                            conv1d_kws[0])\n",
    "        self.maxpool1d = MaxPool1d(2, 2)\n",
    "        self.conv2 = Conv1d(conv1d_channels[0], conv1d_channels[1],\n",
    "                            conv1d_kws[1], 1)\n",
    "        dense_dim = int((self.k - 2) / 2 + 1)\n",
    "        dense_dim = (dense_dim - conv1d_kws[1] + 1) * conv1d_channels[1]\n",
    "        self.lin1 = Linear(dense_dim, 128)\n",
    "        self.lin2 = Linear(128, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        xs = [x]\n",
    "        for conv in self.convs:\n",
    "            xs += [torch.tanh(conv(xs[-1], edge_index))]\n",
    "        x = torch.cat(xs[1:], dim=-1)\n",
    "\n",
    "        # Global pooling.\n",
    "\n",
    "        x = global_sort_pool(x, batch, self.k)\n",
    "\n",
    "        x = x.unsqueeze(1)  # [num_graphs, 1, k * hidden]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool1d(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # [num_graphs, dense_dim]\n",
    "\n",
    "        \n",
    "        # MLP.\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beautiful-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data.x, data.edge_index, data.batch)\n",
    "        loss = BCEWithLogitsLoss()(logits.view(-1), data.y.to(torch.float))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "\n",
    "    return total_loss / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "patient-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    y_pred, y_true = [], []\n",
    "    for data in loader:\n",
    "#         print(data)\n",
    "        data = data.to(device)\n",
    "        logits = model(data.x, data.edge_index, data.batch)\n",
    "        y_pred.append(logits.view(-1).cpu())\n",
    "        y_true.append(data.y.view(-1).cpu().to(torch.float))\n",
    "\n",
    "#     print(y_pred, y_true)\n",
    "    return roc_auc_score(torch.cat(y_true), torch.cat(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-prague",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "apparent-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "intense-municipality",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "cora = Planetoid(root=os.getcwd(), name='Cora')\n",
    "\n",
    "cora_train_dataset = SEALDataset(cora, num_hops=2, split='train')\n",
    "cora_val_dataset = SEALDataset(cora, num_hops=2, split='val')\n",
    "cora_test_dataset = SEALDataset(cora, num_hops=2, split='test')\n",
    "\n",
    "cora_train_loader = DataLoader(cora_train_dataset, batch_size=32, shuffle=True)\n",
    "cora_val_loader = DataLoader(cora_val_dataset, batch_size=32)\n",
    "cora_test_loader = DataLoader(cora_test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "patent-passport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEALDataset(17952)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "resistant-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = DGCNN(hidden_channels=32, num_layers=3).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bored-bedroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[2155], edge_index=[2, 7254], x=[2155, 136], y=[32], z=[2155])\n",
      "Batch(batch=[1894], edge_index=[2, 5896], x=[1894, 136], y=[32], z=[1894])\n",
      "Batch(batch=[2382], edge_index=[2, 7896], x=[2382, 136], y=[32], z=[2382])\n",
      "Batch(batch=[1698], edge_index=[2, 5468], x=[1698, 136], y=[32], z=[1698])\n",
      "Batch(batch=[2191], edge_index=[2, 6692], x=[2191, 136], y=[32], z=[2191])\n",
      "Batch(batch=[2028], edge_index=[2, 6402], x=[2028, 136], y=[32], z=[2028])\n",
      "Batch(batch=[2287], edge_index=[2, 7266], x=[2287, 136], y=[32], z=[2287])\n",
      "Batch(batch=[2826], edge_index=[2, 9558], x=[2826, 136], y=[32], z=[2826])\n",
      "Batch(batch=[1590], edge_index=[2, 4832], x=[1590, 136], y=[32], z=[1590])\n",
      "Batch(batch=[1997], edge_index=[2, 6262], x=[1997, 136], y=[32], z=[1997])\n",
      "Batch(batch=[2060], edge_index=[2, 6396], x=[2060, 136], y=[32], z=[2060])\n",
      "Batch(batch=[1421], edge_index=[2, 4062], x=[1421, 136], y=[32], z=[1421])\n",
      "Batch(batch=[1619], edge_index=[2, 4910], x=[1619, 136], y=[32], z=[1619])\n",
      "Batch(batch=[2441], edge_index=[2, 7680], x=[2441, 136], y=[32], z=[2441])\n",
      "Batch(batch=[1412], edge_index=[2, 4054], x=[1412, 136], y=[32], z=[1412])\n",
      "Batch(batch=[2127], edge_index=[2, 6418], x=[2127, 136], y=[32], z=[2127])\n",
      "Batch(batch=[1066], edge_index=[2, 3244], x=[1066, 136], y=[14], z=[1066])\n",
      "[tensor([ 2.1482,  1.8427,  1.6325,  0.0291,  0.0321,  3.0573,  2.0503,  3.1804,\n",
      "         2.6460,  1.6126,  0.7838,  3.1826, -0.6199,  1.2565,  1.7203,  0.4845,\n",
      "         3.5382,  2.6832,  3.1719,  1.7727,  3.3519,  2.7140, -0.9674, -1.2139,\n",
      "         1.2535,  3.3618, -1.5695, -0.5454,  2.6165,  0.6701, -1.0197,  3.6237]), tensor([ 2.8601,  1.6786,  2.6710,  2.5697,  4.2211, -0.2185,  2.5107,  0.7537,\n",
      "         1.5420,  0.2592,  4.6293, -1.3334,  1.0501,  0.0556,  0.6473, -1.2557,\n",
      "        -0.6236,  1.5872,  3.7546,  1.7651,  1.2724,  4.4303,  2.3380,  3.0922,\n",
      "         4.0688,  2.1184,  3.4067, -0.1031,  3.7566,  3.2124,  3.4481,  2.6005]), tensor([ 2.5751e+00,  3.2335e+00, -8.3973e-01,  1.1204e+00,  3.7991e+00,\n",
      "         2.4701e+00,  3.7678e+00,  2.5242e+00,  1.8361e+00, -9.1818e-01,\n",
      "         3.0113e+00, -4.8918e-01,  2.6222e+00,  2.6435e+00,  8.7808e-01,\n",
      "         4.0990e-01,  1.2268e+00,  2.6463e+00, -1.0688e+00, -6.6924e-01,\n",
      "         4.0015e+00, -3.6419e-01,  1.5541e-01, -3.1960e-01,  3.4778e+00,\n",
      "         3.3390e+00,  3.3259e+00, -6.0440e-01,  4.4303e+00,  3.2506e+00,\n",
      "         1.6208e-03,  3.2423e-01]), tensor([ 1.5553,  4.1065, -0.4275,  4.8831, -0.2590,  0.3242, -0.2099, -0.0107,\n",
      "         1.4581,  1.5586, -0.5682,  0.4424,  2.4455,  2.9936,  2.2810,  3.6737,\n",
      "        -1.5468,  3.0407, -1.3165,  3.6722, -1.0079, -1.3740,  2.2044,  3.8036,\n",
      "         2.2425,  2.6123,  0.3923,  2.1102, -0.9612, -1.1736,  1.3442, -1.1805]), tensor([ 0.6082,  2.5952,  2.7334, -1.0834, -1.0541, -1.4429, -0.3439,  1.9367,\n",
      "        -0.5897,  1.9777,  2.8440,  3.1697,  3.2507, -0.9990,  4.2912,  2.6330,\n",
      "         1.4614,  0.6005, -0.9859, -1.1082, -1.3753,  3.2884,  2.0506,  2.8793,\n",
      "         2.5437,  1.0055,  0.9647,  2.4375, -1.0301,  2.9937,  2.3339,  0.7897]), tensor([-1.0598,  3.1832,  0.4157,  0.8200,  3.6353,  3.8583,  3.2218,  3.1699,\n",
      "         2.8997,  1.3625, -0.9734,  3.0486,  3.1390,  2.3815,  2.8864,  0.0233,\n",
      "        -1.4476,  3.9001,  2.1154, -1.1629, -1.1571,  0.1586, -1.4797,  1.0354,\n",
      "         3.3909, -1.3468,  0.3242,  1.1804, -1.0042,  3.0743,  2.9128, -1.2053]), tensor([ 2.4306,  2.6779,  0.0291,  1.9529,  2.6100,  1.0228,  2.8681,  3.7565,\n",
      "         0.6399, -1.1078,  1.8399,  2.5561,  2.2380,  0.2645,  2.9611,  2.6283,\n",
      "         2.5669,  3.2140, -0.5931, -0.9921, -1.0189,  0.5116,  2.6799, -0.4107,\n",
      "         2.6224,  2.8425,  3.1615,  1.4331, -1.5481,  1.2161,  2.3267,  3.4067]), tensor([ 1.4704,  1.2363,  2.6963,  2.1264, -0.2618, -1.0814,  3.5015,  3.2307,\n",
      "         1.4763,  2.7715,  3.6481,  3.8284, -1.0249, -0.8932, -0.8781,  3.5956,\n",
      "         2.6809,  0.0571,  1.7873,  1.5888, -0.1368,  2.4533,  0.0805,  3.0134,\n",
      "         2.7550, -1.0385, -0.2540,  1.6047,  1.1426,  2.7409,  2.8784,  2.3786]), tensor([ 0.3589, -1.2418, -0.8992,  0.4273,  1.6914,  0.7833,  2.9075, -0.6782,\n",
      "        -0.6031, -1.2035, -1.2473, -1.1719, -1.4565,  1.6050, -0.8673, -0.1214,\n",
      "        -0.8175, -1.1017, -1.3975, -1.3989, -1.5477, -1.2627, -0.4770, -1.4875,\n",
      "        -1.0897,  0.7852, -1.0451,  2.2945, -1.3621, -1.5139, -1.0818, -1.5998]), tensor([-1.2101, -1.0962, -1.2713, -1.6034, -1.4832, -0.5083, -1.5117, -1.3281,\n",
      "        -1.3142, -0.5971, -1.4248, -1.5859, -1.3271, -0.6006,  2.8340,  0.1461,\n",
      "         3.2093, -0.8213, -0.9599,  0.7437, -1.4290, -0.7725, -0.0620, -1.5280,\n",
      "        -1.6617, -1.2409, -1.5505, -1.2750, -1.2547, -1.6407, -1.4190, -1.1997]), tensor([-0.9399, -1.5488, -1.4312, -1.2642, -1.3417, -1.5547,  0.1145, -1.5187,\n",
      "        -1.1195, -0.8127, -0.3741, -1.0572, -1.1621, -1.5068, -1.5826, -1.2973,\n",
      "        -1.6825, -0.8068, -1.3701, -1.6433, -1.3854, -0.2258, -1.1516, -0.3497,\n",
      "        -0.3602, -1.0500, -1.4104, -0.8396, -1.3532, -1.5344, -0.1868,  2.5805]), tensor([-0.8296, -1.1363, -0.8756, -0.6917, -1.3574, -1.5802, -1.2513, -1.6713,\n",
      "        -1.0484, -1.6037,  3.0997, -1.0624, -0.6222, -1.2112, -1.1018, -0.2677,\n",
      "        -0.9643, -1.2036, -0.6612, -1.6300, -0.5984, -1.0620, -1.5842, -1.4672,\n",
      "        -1.4997, -0.1786, -1.4377, -1.4281, -1.4802, -1.4240, -0.4840, -1.2149]), tensor([-1.2985, -1.4517, -0.7078, -0.5543, -1.5995, -1.5298,  1.8897, -1.0024,\n",
      "        -1.3449, -1.2943, -0.8098, -1.0288, -1.1046,  2.0030, -1.0480, -0.6580,\n",
      "        -1.1116, -1.5197, -1.1593, -1.0868, -0.4770, -1.5472,  2.0328, -1.5775,\n",
      "        -1.2904, -1.5040, -1.5648, -1.2162, -1.0944, -1.3186, -1.3651, -1.4153]), tensor([-1.0324, -1.2036, -0.1214, -1.5109, -1.6671, -1.5538, -1.2729, -1.3534,\n",
      "        -1.3659, -1.3309, -1.2876, -1.2345,  0.7593, -0.5606, -1.2268, -1.5833,\n",
      "        -1.4223, -1.6305, -1.1742, -0.7182, -0.7103, -1.3986, -0.8922, -1.2205,\n",
      "        -1.1802, -0.6610, -1.3615, -0.7883, -1.1459, -0.9021, -0.2593,  0.8179]), tensor([-1.3490, -0.5987, -1.5698, -1.0772, -0.9523, -1.0632, -1.6286, -1.4989,\n",
      "        -1.5550, -0.4683,  0.5850, -1.5520, -1.3470, -1.5055, -1.5092, -0.9355,\n",
      "         0.6279,  0.1769, -1.7166, -1.5516, -1.5517, -1.2958, -1.1366, -1.6222,\n",
      "        -1.1743,  3.2311, -1.3709, -1.6104, -1.3509, -1.2132, -1.6630, -1.3860]), tensor([-1.3152, -1.0634, -0.5109, -0.5924, -1.5972, -1.0685, -1.2000, -1.6132,\n",
      "        -0.8408, -1.2343, -0.7626, -0.9329, -1.3399, -0.2587, -1.6718, -1.2662,\n",
      "         0.1038,  0.7813, -1.0323, -1.6405, -1.6225, -1.1937, -1.5817, -0.0924,\n",
      "        -1.2931, -1.5320, -1.2944, -1.4748, -1.3297, -1.3798, -1.3984, -0.8755]), tensor([-1.2326, -1.2940,  0.3985, -0.7831,  1.5793, -1.6490, -1.5854, -0.7218,\n",
      "        -0.9704, -0.9662, -1.1225, -0.7241, -0.9021, -1.3221])] [tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]\n",
      "Batch(batch=[2865], edge_index=[2, 9694], x=[2865, 136], y=[32], z=[2865])\n",
      "Batch(batch=[2250], edge_index=[2, 7246], x=[2250, 136], y=[32], z=[2250])\n",
      "Batch(batch=[2916], edge_index=[2, 9730], x=[2916, 136], y=[32], z=[2916])\n",
      "Batch(batch=[2512], edge_index=[2, 8116], x=[2512, 136], y=[32], z=[2512])\n",
      "Batch(batch=[3020], edge_index=[2, 10386], x=[3020, 136], y=[32], z=[3020])\n",
      "Batch(batch=[2411], edge_index=[2, 7910], x=[2411, 136], y=[32], z=[2411])\n",
      "Batch(batch=[2108], edge_index=[2, 6916], x=[2108, 136], y=[32], z=[2108])\n",
      "Batch(batch=[2647], edge_index=[2, 9022], x=[2647, 136], y=[32], z=[2647])\n",
      "Batch(batch=[2525], edge_index=[2, 8126], x=[2525, 136], y=[32], z=[2525])\n",
      "Batch(batch=[2585], edge_index=[2, 8384], x=[2585, 136], y=[32], z=[2585])\n",
      "Batch(batch=[1903], edge_index=[2, 6134], x=[1903, 136], y=[32], z=[1903])\n",
      "Batch(batch=[2103], edge_index=[2, 6658], x=[2103, 136], y=[32], z=[2103])\n",
      "Batch(batch=[2072], edge_index=[2, 6734], x=[2072, 136], y=[32], z=[2072])\n",
      "Batch(batch=[1628], edge_index=[2, 5056], x=[1628, 136], y=[32], z=[1628])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[3520], edge_index=[2, 12316], x=[3520, 136], y=[32], z=[3520])\n",
      "Batch(batch=[3038], edge_index=[2, 10136], x=[3038, 136], y=[32], z=[3038])\n",
      "Batch(batch=[1753], edge_index=[2, 5532], x=[1753, 136], y=[32], z=[1753])\n",
      "Batch(batch=[1644], edge_index=[2, 4840], x=[1644, 136], y=[32], z=[1644])\n",
      "Batch(batch=[1725], edge_index=[2, 5102], x=[1725, 136], y=[32], z=[1725])\n",
      "Batch(batch=[1985], edge_index=[2, 6220], x=[1985, 136], y=[32], z=[1985])\n",
      "Batch(batch=[1914], edge_index=[2, 5922], x=[1914, 136], y=[32], z=[1914])\n",
      "Batch(batch=[1310], edge_index=[2, 3846], x=[1310, 136], y=[32], z=[1310])\n",
      "Batch(batch=[1330], edge_index=[2, 3762], x=[1330, 136], y=[32], z=[1330])\n",
      "Batch(batch=[1344], edge_index=[2, 3742], x=[1344, 136], y=[32], z=[1344])\n",
      "Batch(batch=[1525], edge_index=[2, 4568], x=[1525, 136], y=[32], z=[1525])\n",
      "Batch(batch=[1487], edge_index=[2, 4046], x=[1487, 136], y=[32], z=[1487])\n",
      "Batch(batch=[1662], edge_index=[2, 5012], x=[1662, 136], y=[32], z=[1662])\n",
      "Batch(batch=[1891], edge_index=[2, 5992], x=[1891, 136], y=[32], z=[1891])\n",
      "Batch(batch=[1550], edge_index=[2, 4444], x=[1550, 136], y=[32], z=[1550])\n",
      "Batch(batch=[1672], edge_index=[2, 5052], x=[1672, 136], y=[32], z=[1672])\n",
      "Batch(batch=[1633], edge_index=[2, 4864], x=[1633, 136], y=[32], z=[1633])\n",
      "Batch(batch=[1779], edge_index=[2, 5286], x=[1779, 136], y=[32], z=[1779])\n",
      "Batch(batch=[1626], edge_index=[2, 5168], x=[1626, 136], y=[30], z=[1626])\n",
      "[tensor([ 1.3102,  3.1370, -1.1740,  0.8667,  3.1137,  2.3631,  1.3090,  1.6126,\n",
      "         0.2073,  3.9169,  2.3044,  2.9272,  3.0920,  3.1693,  2.6686,  0.2819,\n",
      "         2.4964,  3.4341,  3.4450,  2.1458,  3.5183,  2.1929,  2.9562, -0.9647,\n",
      "         2.6302,  3.2685,  3.0525,  3.2651,  3.2203,  1.8672,  3.2119,  1.1179]), tensor([-0.9369, -0.9099,  1.5831, -1.3652,  3.4068, -1.1399, -0.6492, -1.1593,\n",
      "        -0.7762,  2.8263,  3.3573,  1.3092,  2.5421,  2.5403,  3.5135, -0.9063,\n",
      "        -1.3600,  2.6782,  2.7450,  3.1577,  3.1528,  0.4319,  2.9264,  2.5823,\n",
      "         3.6490,  0.3967,  3.8142, -0.7113,  3.1396, -1.0723, -0.3033, -0.0675]), tensor([ 1.7727,  1.2007,  0.3242,  2.4604,  4.0167,  1.8348,  1.6056,  3.1572,\n",
      "         0.6569, -1.1407,  4.0563, -1.2634,  2.1868,  3.8667,  3.8535, -1.0405,\n",
      "         3.2139,  3.1290,  2.2897,  0.9273,  2.9964, -1.1583,  2.6749,  2.4538,\n",
      "        -1.2941,  2.0457, -1.6909,  2.0038,  1.4446,  3.5683,  3.0476,  0.5754]), tensor([ 3.5827,  0.3242,  2.6304, -0.2220, -1.1077, -0.5135,  3.6271,  1.5369,\n",
      "         2.0909,  2.1302,  1.8824,  2.3666,  3.8790, -1.0079,  3.2028, -0.0909,\n",
      "         2.1527,  0.2416, -1.1688, -1.1374,  2.4615, -0.8464,  3.2012, -1.2062,\n",
      "         3.6501,  2.3472,  0.0588,  3.5516, -0.4993,  4.4770,  2.1024, -0.0545]), tensor([ 2.8147,  2.6691,  2.0252, -1.2090,  3.0900,  2.0457, -0.0885, -1.3916,\n",
      "         3.3677, -1.0466, -1.3531,  3.1660,  3.3573,  3.2103,  2.5756,  2.4972,\n",
      "         3.5474, -1.0084, -1.4240, -0.7330, -1.5792,  2.3112, -1.5361,  2.1802,\n",
      "         3.1050,  2.3754,  3.9803,  1.8775,  2.9915, -1.2447,  3.0062,  3.5961]), tensor([ 2.5396,  3.1258,  2.8055,  0.8654,  3.3320,  2.2802, -0.9778,  0.2760,\n",
      "         3.5670,  2.4927, -1.5406, -1.0255,  3.7291,  2.0071, -0.2860,  2.8860,\n",
      "         2.5389,  1.8357, -0.1510,  2.7156,  3.1956,  0.6860,  3.1512,  0.2185,\n",
      "        -1.2926,  3.3046,  2.1784,  1.8729,  2.2202,  3.3743, -0.2327,  2.5081]), tensor([ 2.7424,  2.9974,  2.0002, -0.0573,  3.0978,  3.3762,  4.4078, -1.3610,\n",
      "         3.2002,  2.4681,  1.8232,  2.7914,  1.7239, -1.2685,  1.0659,  1.6261,\n",
      "        -1.2063, -0.0675,  0.0234,  2.4998, -0.9987,  2.3632,  2.9030,  2.5268,\n",
      "         2.2510,  0.4336, -0.8946,  3.9845, -0.8515, -1.3468, -1.1779,  2.2512]), tensor([ 2.1938, -1.2080, -0.9281,  0.1133,  3.6092,  0.7476,  2.5163, -0.7185,\n",
      "         1.2532,  1.8282,  2.2373,  1.6573,  2.6286,  2.1431,  3.5647,  2.2913,\n",
      "         0.3992,  2.1950,  3.3088, -0.6080,  3.1812, -0.9476,  0.2977,  3.7328,\n",
      "         2.7891,  2.9998, -0.3827, -1.3474,  1.4192, -0.7752,  1.5912,  2.3189]), tensor([-0.0900,  2.8353,  0.2370,  2.1022, -1.4096, -1.5334,  2.6132,  2.3992,\n",
      "         3.5444,  2.8911, -1.2290,  2.9100,  1.5533,  2.3428,  2.4941,  2.4263,\n",
      "         0.3242,  4.0807,  2.6182,  3.7413,  3.0116, -0.8680,  3.2681,  3.2060,\n",
      "        -0.0675,  2.6612,  2.5349,  0.9147,  1.0018,  0.9071,  2.3254, -0.8802]), tensor([ 2.8652,  0.6176,  1.9467, -1.1822, -0.4502,  3.5647,  2.2498, -0.9349,\n",
      "         2.4119,  0.7064, -1.2631,  2.5180,  2.3049,  2.4533,  3.5309, -1.1698,\n",
      "         1.6328, -0.6542,  2.1866, -0.8206,  3.3540,  2.9165,  3.8845,  2.9200,\n",
      "         2.0805,  1.7507, -0.8768,  3.2554,  2.7233,  2.4583,  3.0787, -0.0585]), tensor([ 0.5427,  3.3019, -0.3581,  0.8733, -0.2193,  0.0859,  3.5097,  2.3520,\n",
      "         2.1236,  0.7798, -1.0515,  0.0392, -0.6265,  2.2447, -0.7856, -0.8693,\n",
      "         3.1313, -1.1723,  1.4687,  2.5173,  0.8806,  2.6846,  0.0466, -1.3069,\n",
      "        -1.4239,  3.0444,  1.6065, -1.1614,  3.1873, -0.4502,  3.0778,  0.3151]), tensor([ 3.1664, -1.6016, -1.2988,  2.0991,  2.9728,  0.9585, -0.9296, -0.8172,\n",
      "         2.3933,  2.0485, -0.2054,  1.9110,  2.4997, -0.7570,  2.0797,  0.5809,\n",
      "        -1.4041,  2.4166,  1.6640,  0.6424,  3.3766,  0.3242,  0.2165,  2.5556,\n",
      "         0.3242,  0.4368,  1.7157,  3.1089,  0.2416,  3.6847, -0.8693,  3.6368]), tensor([-1.5854,  2.5321, -1.1510,  0.3242,  1.1559, -0.8246,  3.5456, -0.8946,\n",
      "         3.3909, -1.5660, -1.0453,  3.6258,  3.8461,  0.9540,  2.5478,  3.0811,\n",
      "         2.8609,  3.1807,  2.4927,  2.4134, -1.0190,  3.8097,  2.9463,  2.2297,\n",
      "         3.0675,  2.2916,  3.0418,  2.6291,  0.1119,  3.1132, -1.1805,  3.3482]), tensor([ 0.0275,  3.1564,  3.0913,  0.9288,  3.6046,  1.3420,  1.0074,  2.5265,\n",
      "        -0.3642,  0.7372,  3.5191,  1.4464, -0.7457,  1.9169,  2.0343,  1.2969,\n",
      "         2.6688, -1.5678,  2.5552, -1.4367,  0.2416, -1.4488,  4.0194, -0.8049,\n",
      "        -0.7214,  2.8939, -0.4731,  3.3208,  3.5853,  2.9582, -0.7293,  0.6233]), tensor([-0.5345, -1.1206, -1.4822,  2.6781, -1.1838, -0.8471,  2.6331, -1.5897,\n",
      "         3.0260, -0.3396,  1.5820, -0.7268,  2.4801,  3.4304,  2.0684, -0.6002,\n",
      "         2.7557, -1.1034, -1.0088, -0.7185, -1.2424,  3.1582,  0.3242,  1.6707,\n",
      "         2.2236,  0.2416,  1.7566,  3.0717,  3.1150, -1.0322,  2.7160,  0.9456]), tensor([-0.8878, -0.9954,  2.9768, -0.5812, -1.4960,  1.5612, -1.1570, -0.8775,\n",
      "         2.7163,  2.9730,  0.1033,  2.4533, -1.3039,  2.5379,  3.3079,  1.6487,\n",
      "         2.8526, -0.0479,  2.8276,  2.9705,  1.9441,  3.7250,  0.0957, -0.7503,\n",
      "         1.4687,  3.3493,  2.6522, -1.4776,  3.2787, -0.9687,  3.7564, -0.8916]), tensor([ 2.1595,  0.7082,  2.2028,  3.0257,  3.1007,  2.6781,  2.5098,  1.8558,\n",
      "         2.8028, -0.8058,  2.1739,  1.4433, -1.0079,  3.2082,  3.5082, -1.2039,\n",
      "        -1.6542, -1.1370, -1.3585, -1.3105, -1.2027, -1.1220, -0.7314, -0.9035,\n",
      "        -1.2389, -1.3704, -1.3148, -1.6582, -1.5823, -1.2256, -1.2736, -1.4800]), tensor([-1.2083, -0.4768, -1.4303, -1.4657, -1.2773, -1.5016, -0.9932, -0.3836,\n",
      "        -1.3793, -1.6404, -0.9782,  2.8435, -0.6356, -1.4098, -0.8921, -1.2181,\n",
      "        -1.6299, -0.0872, -1.2937, -1.4006, -1.3131, -0.5998, -0.9078, -0.7150,\n",
      "        -1.2390, -1.5608,  1.0737,  0.9659, -1.1185, -1.2217, -1.4987, -1.4368]), tensor([-1.6339, -1.5994, -1.3158, -1.1701, -1.6657, -1.5749, -1.5032, -1.2248,\n",
      "        -0.0917, -1.0554, -1.2826, -0.8745, -1.1191, -0.7738, -1.2675, -0.8114,\n",
      "        -1.1098, -0.8277, -1.0303, -1.0216,  2.6343, -0.7647, -1.4792, -1.3216,\n",
      "         0.4492, -1.4586, -0.5341, -1.2233, -1.6674, -1.6411, -1.1368, -1.2386]), tensor([-1.0376, -1.5505, -1.3001, -1.5469, -1.5942, -1.4459, -1.5803, -0.8469,\n",
      "         2.4331, -1.1664, -1.2823, -1.4100, -1.3475, -1.5737, -1.5401, -1.3392,\n",
      "        -1.4612, -0.5846, -1.0433, -1.2436,  2.6777, -1.0058, -1.4428, -1.3326,\n",
      "        -1.2975, -1.3948, -0.6052, -0.4972, -1.4799, -1.6211,  1.4305,  2.2399]), tensor([-1.3133, -1.2921, -0.7031, -1.6281,  0.3531, -1.4962, -0.9788, -1.1849,\n",
      "        -1.2323, -1.1584, -0.9932, -1.4371, -0.0040, -0.3357, -0.3498, -1.5622,\n",
      "        -1.5440, -1.2214, -1.1726, -1.4362, -0.8098, -0.7705, -1.4453, -1.2468,\n",
      "        -1.3870, -1.6176, -1.3109, -0.4278, -1.2284, -1.3067, -1.6960, -1.3338]), tensor([-0.8781,  2.7664, -1.1957, -1.3931,  2.8932, -1.5115, -0.7315, -1.1098,\n",
      "        -1.6142, -1.4676, -1.5730, -1.2793, -1.5164, -1.4483, -0.6275, -0.9175,\n",
      "        -1.5067, -0.7203, -1.5641, -1.4509, -0.6293, -1.3150, -0.9062, -1.4002,\n",
      "        -1.3644, -1.1152, -0.3976, -1.2947, -0.6215, -1.0693, -1.5981, -1.3452]), tensor([-0.4283, -1.6084, -0.4590, -0.8175,  2.7528, -1.5450, -1.2646, -1.1648,\n",
      "        -1.2926, -1.6070, -1.5695, -0.4750, -1.5272, -1.5324, -0.9937, -1.3480,\n",
      "        -1.5816, -1.2524, -1.3369, -1.2852, -1.6139, -1.3405, -1.3287, -0.2013,\n",
      "        -1.5470, -1.4334, -0.4757, -1.1408, -1.2122, -1.4879, -1.5364, -1.3918]), tensor([-1.6725, -0.7218, -1.6684, -0.2944, -0.6324, -1.6361, -1.5520, -1.1654,\n",
      "        -1.3008, -1.3829, -1.2467, -0.8813, -1.4403, -1.3081, -1.3451, -1.1738,\n",
      "        -0.9429, -1.0639,  0.3242, -1.5699, -1.5926,  1.0142, -1.3206,  0.8552,\n",
      "        -1.3084, -1.3311, -1.4764, -1.2275, -1.5201, -1.1723, -0.9294, -1.2749]), tensor([-1.2344, -1.2258, -1.2820, -0.9243, -1.4153, -1.2128, -1.3387, -1.4546,\n",
      "        -1.1718, -1.2115, -0.6563, -1.5652, -0.0595, -0.5743, -0.8771,  2.9274,\n",
      "        -1.4366, -1.2471, -1.4471, -1.2247, -1.5394, -1.1436, -1.5479, -1.5204,\n",
      "        -1.4522, -1.5065, -1.6279, -1.7080, -1.3567, -1.1639, -1.5346, -1.1330]), tensor([-1.1910, -1.5479, -1.2619, -0.8648, -1.4977, -1.2075, -0.5613,  1.1042,\n",
      "        -1.0443, -1.1327, -1.1849, -0.2383, -1.1951, -1.2409, -0.4472, -1.5337,\n",
      "        -1.3140, -0.9944, -0.7553, -1.5545, -1.2025,  0.1545, -1.3200, -1.5324,\n",
      "        -0.2898, -1.2861, -0.9072, -1.4464, -1.5368, -1.6128, -1.1750, -0.8493]), tensor([-1.5768, -0.3629, -1.5310, -1.3254, -1.5055, -1.2870, -1.0850, -1.3084,\n",
      "        -1.6243, -0.2448, -1.3504, -0.2774, -1.5763, -1.1120, -1.2699, -1.5946,\n",
      "        -1.2447, -1.2412, -1.3233, -1.2631, -1.3600, -0.4931, -1.3416, -0.9159,\n",
      "        -1.4438,  0.3242,  0.9254, -1.1920, -1.5541, -1.5869, -0.6199, -1.2596]), tensor([ 1.4521, -0.3336, -1.5960, -1.0902,  1.1136, -0.9842, -1.2314, -0.1214,\n",
      "         0.3985, -1.5928, -1.4818, -1.6245, -1.4511, -1.1711, -1.1129, -1.4394,\n",
      "        -1.5400, -1.0297, -1.4987, -1.0820, -1.3580, -0.6264, -1.3053, -1.3595,\n",
      "        -0.5959, -1.2876, -0.5737, -1.0647, -1.2216, -1.5474, -1.3615,  0.3985]), tensor([-1.4681, -0.9852, -1.1242,  0.1616, -1.2996, -1.5002, -1.0720, -1.2497,\n",
      "        -1.4078, -1.1507, -0.9871, -1.2744, -1.4333,  2.3566, -1.5513, -1.2413,\n",
      "        -1.3500,  0.0799, -0.8789, -1.4370, -0.6973, -0.8865, -1.0061, -1.3467,\n",
      "        -1.3678, -1.5051, -0.9907, -1.4990, -1.3025, -0.6364, -0.2725, -1.1797]), tensor([-1.0363, -0.1002, -1.2960, -1.5127, -0.9153, -1.4956, -0.7809, -1.1311,\n",
      "        -1.3734, -1.3246, -1.1353, -1.2425, -0.2919, -1.1285, -1.1670, -1.0810,\n",
      "        -1.2261, -1.6167, -1.5965, -1.6190, -1.2622, -1.4540, -0.9123, -0.9317,\n",
      "        -1.3388, -1.0902, -0.5776, -1.4234, -1.2905, -1.5853,  0.3985, -0.5147]), tensor([-0.8064, -1.3689, -1.2876, -1.3187, -1.2702, -1.5854, -0.8117, -1.5851,\n",
      "        -1.3398, -1.2684, -1.4489, -0.1669, -0.8958, -1.1677, -1.3283, -1.2991,\n",
      "        -1.4536, -1.4992, -1.5151, -0.8895, -1.2509, -1.6767, -0.2437, -1.4554,\n",
      "        -1.4993, -1.3363, -1.4287, -1.5166, -0.8587, -0.6184, -1.5082, -1.3877]), tensor([-1.2623, -1.0599, -0.8493, -1.3248, -1.2587, -1.5800, -1.0191,  0.5660,\n",
      "        -0.1111,  2.7069, -1.4301, -1.2111, -0.2919, -0.0719, -1.6029, -0.8547,\n",
      "        -1.5786, -1.2363, -1.3360, -1.1330, -0.3103, -1.2257, -0.9292, -1.5664,\n",
      "        -0.4770, -1.3157, -1.1926, -1.4909, -0.2498, -1.5395, -1.3976, -1.0709]), tensor([-1.5189, -1.3119, -1.1876, -0.6207, -1.5989, -1.5891,  1.0140, -1.2625,\n",
      "        -0.9907, -1.1044, -1.5161, -0.5329, -1.5312, -1.1774, -1.5493, -1.4903,\n",
      "        -1.1768, -1.0353, -1.3218, -1.3935, -0.1028, -1.3054, -1.1525, -1.1595,\n",
      "        -0.1214,  0.0172, -1.2875, -1.5445, -1.6158, -1.0467])] [tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])]\n",
      "Epoch: 01, Loss: 0.5237, Val: 0.8906, Test: 0.8903\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-1d6ec3754f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_val_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m51\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcora_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mval_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcora_val_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_auc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_auc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-53fd2a034377>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/june/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    190\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_auc = test_auc = 0\n",
    "for epoch in range(1, 51):\n",
    "    loss = train(cora_train_loader)\n",
    "    val_auc = test(cora_val_loader)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        test_auc = test(cora_test_loader)\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-ensemble",
   "metadata": {},
   "source": [
    "# My Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "particular-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset =  MyDataset(num_hops=2, root=os.path.join(os.getcwd(), \"hw2_data\", \"dataset1\"), split=\"train\")\n",
    "val_dataset =  MyDataset(num_hops=2, root=os.path.join(os.getcwd(), \"hw2_data\", \"dataset1\"), split=\"valid\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "packed-mailing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyDataset(12897)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "copyrighted-ordinary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 0], x=[2, 1518], y=[1], z=[2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "subjective-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = DGCNN(hidden_channels=32, num_layers=3).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "date_time = datetime.strftime(datetime.now(), \"%Y-%m-%d_%H-%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-modern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Model\n",
      "\n",
      "Epoch: 01, Loss: 0.6093, Val: 0.8282\n",
      "Save Model\n",
      "\n",
      "Epoch: 02, Loss: 0.4805, Val: 0.8583\n",
      "Save Model\n",
      "\n",
      "Epoch: 03, Loss: 0.4386, Val: 0.8754\n",
      "Save Model\n",
      "\n",
      "Epoch: 04, Loss: 0.4081, Val: 0.8832\n",
      "Save Model\n",
      "\n",
      "Epoch: 05, Loss: 0.3877, Val: 0.8887\n",
      "Save Model\n",
      "\n",
      "Epoch: 06, Loss: 0.3698, Val: 0.8939\n",
      "Save Model\n",
      "\n",
      "Epoch: 07, Loss: 0.3534, Val: 0.8953\n",
      "Save Model\n",
      "\n",
      "Epoch: 08, Loss: 0.3411, Val: 0.8976\n",
      "Save Model\n",
      "\n",
      "Epoch: 09, Loss: 0.3294, Val: 0.9006\n",
      "Epoch: 10, Loss: 0.3170, Val: 0.9006\n",
      "Save Model\n",
      "\n",
      "Epoch: 11, Loss: 0.3072, Val: 0.9033\n",
      "Epoch: 12, Loss: 0.3000, Val: 0.9031\n",
      "Save Model\n",
      "\n",
      "Epoch: 13, Loss: 0.2875, Val: 0.9066\n",
      "Save Model\n",
      "\n",
      "Epoch: 14, Loss: 0.2788, Val: 0.9071\n",
      "Save Model\n",
      "\n",
      "Epoch: 15, Loss: 0.2705, Val: 0.9087\n",
      "Save Model\n",
      "\n",
      "Epoch: 16, Loss: 0.2684, Val: 0.9104\n",
      "Save Model\n",
      "\n",
      "Epoch: 17, Loss: 0.2578, Val: 0.9126\n",
      "Save Model\n",
      "\n",
      "Epoch: 18, Loss: 0.2515, Val: 0.9149\n",
      "Save Model\n",
      "\n",
      "Epoch: 19, Loss: 0.2481, Val: 0.9166\n",
      "Save Model\n",
      "\n",
      "Epoch: 20, Loss: 0.2435, Val: 0.9188\n",
      "Epoch: 21, Loss: 0.2375, Val: 0.9174\n",
      "Epoch: 22, Loss: 0.2296, Val: 0.9184\n",
      "Save Model\n",
      "\n",
      "Epoch: 23, Loss: 0.2285, Val: 0.9196\n",
      "Epoch: 24, Loss: 0.2230, Val: 0.9179\n",
      "Save Model\n",
      "\n",
      "Epoch: 25, Loss: 0.2251, Val: 0.9211\n",
      "Save Model\n",
      "\n",
      "Epoch: 26, Loss: 0.2172, Val: 0.9225\n",
      "Epoch: 27, Loss: 0.2114, Val: 0.9223\n",
      "Epoch: 28, Loss: 0.2102, Val: 0.9225\n",
      "Save Model\n",
      "\n",
      "Epoch: 29, Loss: 0.2034, Val: 0.9242\n",
      "Save Model\n",
      "\n",
      "Epoch: 30, Loss: 0.1994, Val: 0.9246\n",
      "Save Model\n",
      "\n",
      "Epoch: 31, Loss: 0.2003, Val: 0.9271\n",
      "Save Model\n",
      "\n",
      "Epoch: 32, Loss: 0.1935, Val: 0.9285\n",
      "Save Model\n",
      "\n",
      "Epoch: 33, Loss: 0.1880, Val: 0.9304\n",
      "Save Model\n",
      "\n",
      "Epoch: 34, Loss: 0.1880, Val: 0.9310\n",
      "Save Model\n",
      "\n",
      "Epoch: 35, Loss: 0.1836, Val: 0.9317\n",
      "Save Model\n",
      "\n",
      "Epoch: 36, Loss: 0.1853, Val: 0.9320\n",
      "Epoch: 37, Loss: 0.1773, Val: 0.9315\n",
      "Save Model\n",
      "\n",
      "Epoch: 38, Loss: 0.1750, Val: 0.9322\n",
      "Save Model\n",
      "\n",
      "Epoch: 39, Loss: 0.1711, Val: 0.9354\n"
     ]
    }
   ],
   "source": [
    "best_val_auc = test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train(train_loader)\n",
    "    val_auc = test(val_loader)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "#         test_auc = test(test_loader)\n",
    "\n",
    "        checkpoint = {\n",
    "            'model_stat': model.state_dict(),\n",
    "            'optimizer_stat': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, os.path.join(os.getcwd(), \n",
    "                                            \"hw2_data\", \n",
    "                                            \"dataset1\", \n",
    "                                            \"{}.pth\".format(date_time)))\n",
    "        print(\"Save Model\\n\")\n",
    "        \n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-polyester",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
