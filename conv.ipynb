{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "central-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import os.path as osp\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from torch import Tensor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "broadband-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coordinate-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "reported-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    num_ent = 2708\n",
    "    embed_dim = 1500\n",
    "    inp_drop = 0\n",
    "    feat_drop = 0 # 0.5\n",
    "    hid_drop = 0 # 0.5\n",
    "    perm = 1\n",
    "    k_w = 30\n",
    "    k_h = 50\n",
    "    num_filt = 96\n",
    "    ker_sz = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "false-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "    \n",
    "    def __init__(self, root, split=\"train\"):\n",
    "        \n",
    "        # Read node features\n",
    "        content = pd.read_csv(os.path.join(root, \"content.csv\"), delimiter=\"\\t\", header=None)\n",
    "        content = content.sort_values(by=[0]).loc[:, 1:].to_numpy()\n",
    "#         content = torch.from_numpy(content)\n",
    "        self.features = content\n",
    "        \n",
    "        \n",
    "        self.links = None\n",
    "        if split == \"train\":\n",
    "            self.links = pd.read_csv(os.path.join(root, \"train.csv\"))\n",
    "        else:\n",
    "            self.links = pd.read_csv(os.path.join(root, \"test.csv\"))\n",
    "            \n",
    "        tmp = pd.DataFrame(data={\n",
    "                                \"from\": self.links[\"to\"], \n",
    "                                \"to\": self.links[\"from\"],\n",
    "                                \"label\": self.links[\"label\"]})\n",
    "        self.links = pd.concat([self.links, tmp], ignore_index=True)\n",
    "        self.links = self.links.drop_duplicates()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.links)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        row = self.links.iloc[idx]\n",
    "\n",
    "        follower, followee, label = row[\"from\"], row[\"to\"], row[\"label\"]\n",
    "\n",
    "        follower_feat = self.features[follower]\n",
    "        followee_feat = self.features[followee]\n",
    "        \n",
    "        return follower, followee, follower_feat, followee_feat, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "unlikely-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chequer_perm(perm=1, k_w=30, k_h=50):\n",
    "    \"\"\"\n",
    "    Function to generate the chequer permutation required for InteractE model\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    embed_dim = k_w * k_h\n",
    "    ent_perm  = np.int32([np.random.permutation(embed_dim) for _ in range(perm)])\n",
    "#     print(ent_perm)\n",
    "    rel_perm  = np.int32([np.random.permutation(embed_dim) for _ in range(perm)])\n",
    "#     print(rel_perm)\n",
    "\n",
    "    comb_idx = []\n",
    "    for k in range(perm):\n",
    "        temp = []\n",
    "        ent_idx, rel_idx = 0, 0\n",
    "\n",
    "        for i in range(embed_dim):\n",
    "            if k % 2 == 0:\n",
    "                if i % 2 == 0:\n",
    "                    temp.append(ent_perm[k, ent_idx]); ent_idx += 1;\n",
    "                    temp.append(rel_perm[k, rel_idx]+embed_dim); rel_idx += 1;\n",
    "                else:\n",
    "                    temp.append(rel_perm[k, rel_idx]+embed_dim); rel_idx += 1;\n",
    "                    temp.append(ent_perm[k, ent_idx]); ent_idx += 1;\n",
    "            else:\n",
    "                if i % 2 == 0:\n",
    "                    temp.append(rel_perm[k, rel_idx]+embed_dim); rel_idx += 1;\n",
    "                    temp.append(ent_perm[k, ent_idx]); ent_idx += 1;\n",
    "                else:\n",
    "                    temp.append(ent_perm[k, ent_idx]); ent_idx += 1;\n",
    "                    temp.append(rel_perm[k, rel_idx]+embed_dim); rel_idx += 1;\n",
    "\n",
    "        comb_idx.append(temp)\n",
    "\n",
    "    chequer_perm = torch.LongTensor(np.int32(comb_idx))\n",
    "    return chequer_perm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "marine-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractE(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Proposed method in the paper. Refer Section 6 of the paper for mode details \n",
    "    Parameters\n",
    "    ----------\n",
    "    params:        \tHyperparameters of the model\n",
    "    chequer_perm:   Reshaping to be used by the model\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The InteractE model instance\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, params, chequer_perm):\n",
    "        super(InteractE, self).__init__()\n",
    "\n",
    "        self.p = params\n",
    "        self.ent_embed = torch.nn.Embedding(self.p.num_ent, self.p.embed_dim-1433, padding_idx=None); # xavier_normal_(self.ent_embed.weight)\n",
    "        self.inp_drop = torch.nn.Dropout(self.p.inp_drop)\n",
    "        self.hidden_drop = torch.nn.Dropout(self.p.hid_drop)\n",
    "        self.feature_map_drop = torch.nn.Dropout2d(self.p.feat_drop)\n",
    "        self.bn0 = torch.nn.BatchNorm2d(self.p.perm)\n",
    "\n",
    "        flat_sz_h  = self.p.k_h\n",
    "        flat_sz_w  = 2*self.p.k_w\n",
    "        self.padding  = 0\n",
    "\n",
    "        self.bn1  = torch.nn.BatchNorm2d(self.p.num_filt*self.p.perm)\n",
    "        self.flat_sz  = flat_sz_h * flat_sz_w * self.p.num_filt*self.p.perm\n",
    "\n",
    "        self.bn2 = torch.nn.BatchNorm1d(self.p.embed_dim)\n",
    "#         self.fc  = torch.nn.Linear(self.flat_sz, self.p.embed_dim)\n",
    "        self.fc = torch.nn.Linear(self.flat_sz, 1)\n",
    "        self.chequer_perm = chequer_perm\n",
    "\n",
    "#         self.register_parameter('bias', Parameter(torch.zeros(self.p.num_ent)))\n",
    "        self.register_parameter('conv_filt', Parameter(torch.zeros(self.p.num_filt, 1, self.p.ker_sz,  self.p.ker_sz))); # xavier_normal_(self.conv_filt)\n",
    "\n",
    "    def circular_padding_chw(self, batch, padding):\n",
    "        upper_pad = batch[..., -padding:, :]\n",
    "        lower_pad = batch[..., :padding, :]\n",
    "        temp = torch.cat([upper_pad, batch, lower_pad], dim=2)\n",
    "\n",
    "        left_pad = temp[..., -padding:]\n",
    "        right_pad = temp[..., :padding]\n",
    "        padded = torch.cat([left_pad, temp, right_pad], dim=3)\n",
    "        return padded\n",
    "\n",
    "    def forward(self, follower, followee, follower_id, followee_id, strategy='one_to_x'):\n",
    "#         sub_emb = self.ent_embed(sub)\n",
    "#         rel_emb = self.rel_embed(rel)\n",
    "\n",
    "        follower_emb = self.ent_embed(follower_id)\n",
    "        if isinstance(follower, np.ndarray):\n",
    "            follower = torch.from_numpy(follower)\n",
    "        follower_emb = torch.cat((follower, follower_emb), dim=-1)\n",
    "    \n",
    "#         print(follower_emb.size())\n",
    "        \n",
    "        followee_emb = self.ent_embed(followee_id)\n",
    "        if isinstance(followee, np.ndarray):\n",
    "            followee = torch.from_numpy(followee)\n",
    "        followee_emb = torch.cat((followee, followee_emb), dim=-1)\n",
    "        \n",
    "        comb_emb = torch.cat([follower_emb, followee_emb], dim=-1)\n",
    "        chequer_perm = comb_emb[:, self.chequer_perm] # batch, 1, embed_size\n",
    "        \n",
    "#         print(chequer_perm)\n",
    "#         print(chequer_perm.size())\n",
    "        \n",
    "        stack_inp = chequer_perm.reshape((-1, self.p.perm, 2*self.p.k_w, self.p.k_h)) # batch, 1, 2*k_w, k_h\n",
    "        \n",
    "#         print(stack_inp.size())\n",
    "        \n",
    "        stack_inp = self.bn0(stack_inp)\n",
    "        \n",
    "        x = self.inp_drop(stack_inp)\n",
    "        x = self.circular_padding_chw(x, self.p.ker_sz//2)\n",
    "#         print(x.size())\n",
    "        x = F.conv2d(x, self.conv_filt.repeat(self.p.perm, 1, 1, 1), padding=self.padding, groups=self.p.perm)\n",
    "#         print(x.size())\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.feature_map_drop(x)\n",
    "        x = x.view(-1, self.flat_sz)\n",
    "        x = self.fc(x) # batch, flat_sz\n",
    "        \n",
    "#         print(x.size())\n",
    "\n",
    "#         x = self.hidden_drop(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = F.relu(x)\n",
    "\n",
    "#         if strategy == 'one_to_n':\n",
    "#             x = torch.mm(x, self.ent_embed.weight.transpose(1,0))\n",
    "#             x += self.bias.expand_as(x)\n",
    "#         else:\n",
    "#             x = torch.mul(x.unsqueeze(1), self.ent_embed(neg_ents)).sum(dim=-1)\n",
    "#             x += self.bias[neg_ents]\n",
    "\n",
    "        pred = torch.sigmoid(x)\n",
    "\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "driven-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "chequer = get_chequer_perm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "civic-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath, device):\n",
    "    \n",
    "    model = InteractE(Args(), chequer).to(device)\n",
    "\n",
    "    if os.path.exists(filepath):\n",
    "        print(\"pretrained finded\")\n",
    "        checkpoint = torch.load(filepath)\n",
    "        model.load_state_dict(checkpoint['model_stat'])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_stat'])\n",
    "\n",
    "    else:\n",
    "        print(\"use a new optimizer\")\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "pharmaceutical-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Dataset(root=osp.join(root, \"hw2_data\", \"dataset1\", \"raw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "vertical-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "interior-burst",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use a new optimizer\n"
     ]
    }
   ],
   "source": [
    "model, optimizer = load_checkpoint(os.path.join(root, \"results\", \"dataset1\", \"conv\", \"weight.pth\"), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "duplicate-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim, loader, device):\n",
    "    \n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    total_loss = 0\n",
    "    for index, data in tqdm(enumerate(loader)):\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        follower, followee, follower_feat, followee_feat, label = data\n",
    "        \n",
    "        follower = follower.to(device)\n",
    "        followee = followee.to(device)\n",
    "        follower_feat = follower_feat.to(device)\n",
    "        followee_feat = followee_feat.to(device)\n",
    "        label = label.to(device).float()\n",
    "\n",
    "        pred = model(follower_feat, followee_feat, follower, followee) \n",
    "        pred = torch.squeeze(pred)\n",
    "        \n",
    "        loss = torch.nn.BCELoss()(pred, label)\n",
    "#         print(pred, label)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    total_loss = total_loss/(index+1)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "under-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(model, loader, device=\"cpu\"):\n",
    "    \n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    y_pred, y_true = [], []\n",
    "    for data in tqdm(loader):\n",
    "        follower, followee, follower_feat, followee_feat, label = data\n",
    "        \n",
    "        follower = follower.to(device)\n",
    "        followee = followee.to(device)\n",
    "        follower_feat = follower_feat.to(device)\n",
    "        followee_feat = followee_feat.to(device)\n",
    "        label = label.to(device).float()\n",
    "        \n",
    "        pred = model(follower_feat, followee_feat, follower, followee) \n",
    "        pred = torch.squeeze(pred)\n",
    "        \n",
    "        y_pred.append(pred.view(-1).cpu())\n",
    "        y_true.append(label.view(-1).cpu())\n",
    "        \n",
    "#     print(torch.cat(y_true), torch.cat(y_pred))\n",
    "\n",
    "    return roc_auc_score(torch.cat(y_true), torch.cat(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-mexico",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "543it [00:03, 138.04it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 23.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save Model\n",
      "Epoch: 1, loss=0.6931515957330033, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 137.35it/s]\n",
      "100%|██████████| 543/543 [00:23<00:00, 23.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss=0.693149410668438, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 143.23it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 24.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss=0.6931480378955328, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 137.55it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 23.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss=0.693147045582478, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 140.79it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 23.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, loss=0.693146312873447, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 140.47it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 24.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss=0.6931457732483388, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 138.00it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 24.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, loss=0.6931453705053523, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 138.68it/s]\n",
      "100%|██████████| 543/543 [00:21<00:00, 25.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss=0.6931450694085923, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 140.53it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 24.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, loss=0.6931448461381551, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 136.34it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 24.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss=0.6931446772034436, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 135.91it/s]\n",
      "100%|██████████| 543/543 [00:21<00:00, 24.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, loss=0.6931445460293174, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 136.35it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 23.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, loss=0.6931444487738565, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 141.42it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 23.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, loss=0.6931443754480688, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 138.16it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 23.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, loss=0.693144314965271, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 137.34it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 23.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, loss=0.6931442748995337, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 139.87it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 23.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, loss=0.6931442442739427, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:04, 128.71it/s]\n",
      "100%|██████████| 543/543 [00:21<00:00, 24.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, loss=0.6931442098064318, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 143.89it/s]\n",
      "100%|██████████| 543/543 [00:21<00:00, 24.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, loss=0.6931441888405253, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 136.30it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 23.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, loss=0.6931441723751539, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 146.54it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 23.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss=0.6931441581051653, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:04, 134.23it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 24.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, loss=0.6931441461403286, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:04, 132.56it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 24.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, loss=0.6931441388955651, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 137.21it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 24.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, loss=0.6931441300042646, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 144.42it/s]\n",
      "100%|██████████| 543/543 [00:22<00:00, 24.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, loss=0.693144124954884, auc=0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "543it [00:03, 140.85it/s]\n",
      " 21%|██        | 115/543 [00:04<00:17, 25.02it/s]"
     ]
    }
   ],
   "source": [
    "auc_max = 0\n",
    "for epoch in range(100):\n",
    "\n",
    "    loss = train(model, optimizer, trainloader, device)\n",
    "    auc = test(model, trainloader)\n",
    "   \n",
    "    if auc > auc_max:\n",
    "        auc_max = auc\n",
    "        \n",
    "        checkpoint = {\n",
    "            'model_stat': model.state_dict(),\n",
    "            'optimizer_stat': optimizer.state_dict(),\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, os.path.join(root, \"results\", \"dataset1\", \"conv\", \"weight.pth\"))\n",
    "        print(\"\\nSave Model\")\n",
    "    \n",
    "    print(\"Epoch: {}, loss={}, auc={}\".format(epoch+1, loss, auc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-enclosure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
